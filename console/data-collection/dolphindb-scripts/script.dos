// shareStreamingTable = select * from objs(true) where type=`REALTIME and form=`TABLE and shared=true
// if(!(`dcp_test in shareStreamingTable.name)){
    // share streamTable(1:0,["ts","id","metric","value"],[TIMESTAMP,LONG,STRING,STRING]) as dcp_test
// }
/*
增加连接
参数：args 为标准json，需要包含以下字段：
commonParams:
name: 连接名称     字符串
protocol: 协议类型 字符串
host: 主机地址     字符串
port: 端口         整数
mqttParams：
username: 用户名   字符串
password: 密码     字符串
使用示例：
args = '{ "name":"emqx", "protocol":"mqtt", "host":"183.134.101.140", "port":1883, "username":"admin1", "password":"DolphinDB123"}' 
dcp_addConnect(args) 
args = '{ "name":"kafka1", "protocol":"kafka", "host":"183.134.101.140", "port":9092}'  
dcp_addConnect(args)
*/

def dcp_addConnect(args){
    connectArgs = parseExpr(args).eval()
    ex=["user",NULL]
    try{
        exits = select * from loadTable("dfs://dataAcquisition","connectInfo") where name = connectArgs[`name]
        if(exits.size()!=0){
            throw("The connection name already exists, please verify the connection information")
        }else{
                id = rand(uuid(),1)[0]
                if(connectArgs[`protocol]=="kafka"){
                    connectArgs[`username]=string(NULL)
                    connectArgs[`password]=string(NULL)    
                }
                connectTable = table(id as id,connectArgs[`name] as name ,connectArgs[`protocol] as protocol,
                connectArgs[`host] as host,connectArgs[`port] as port,connectArgs[`username] as username,connectArgs[`password] as password)
                update connectTable set createTime = now()
                update connectTable set updateTime = now()
                connectTable.reorderColumns!(`id`name`protocol`host`port`username`password`createTime`updateTime)
                loadTable("dfs://dataAcquisition","connectInfo").append!(connectTable)
                writeLog("The "+ upper(connectArgs[`protocol]) +" connection named " + connectArgs[`name]+" successfully added")
                return '{"status":1,"id":"'+string(id)+'"}'
        }
    }catch(ex){
        writeLog("An error occured when adding "+upper(connectArgs[`protocol])+" connection, the reason is:"+ex[1])
    }
    if(ex[1]!=NULL){
        throw(ex[1])
    }
}




/*
修改连接
参数：args 为标准json，可包含以下字段：
commonParams：
id(必选): 连接ID    字符串
name: 连接名称      字符串
host: 主机地址      字符串
port: 端口         整数
mqttParams:
username: 用户名    字符串
password: 密码      字符串
使用示例：
args = '{ "name":"emqx", "id":"cc2a890b-bd79-f243-da4c-7604bc9e4970", "host":"183.134.101.141", "port":1883, "username":"admin1", "password":"DolphinDB123"}'
dcp_updateConnect(args)  
args = '{ "name":"KAFKA", "id":"e5d6a0ed-600d-d701-3fcb-8d046883d517", "host":"183.134.101.142", "port":9092}'  
dcp_updateConnect(args)
*/
args = '{"name":"EMQX1","host":"183.134.101.141","port":1883,"username":"admin1","password":"123456","id":"f2288bc9-615b-2d31-cb66-e6f6d7cdfe91"}'
def dcp_updateConnect(args){
    connectArgs = parseExpr(args).eval()
    ex=["user",NULL]
    tmp = select * from loadTable("dfs://dataAcquisition","connectInfo") where id = uuid(connectArgs[`id])
    try{
        exits = select * from loadTable("dfs://dataAcquisition","connectInfo") 
        where name = connectArgs[`name] and protocol = tmp[`protocol][0] and id != uuid(connectArgs[`id])    
        if(exits.size()!=0){
            throw("The connection name already exists, please verify the connection information")
        }
        for(col in connectArgs.keys()){
            if(col !=`id){ 
                tmp[col]=connectArgs[col]
            }
        }
        tmp[`updateTime]=now()  
        delete from loadTable("dfs://dataAcquisition","connectInfo") where id = uuid(connectArgs[`id])
        loadTable("dfs://dataAcquisition","connectInfo").append!(tmp)
        writeLog("The "+ upper(tmp[`protocol][0]) +" connection named " + connectArgs[`name]+" successfully updated")
        return '{"status":1}'
    }catch(ex){
        writeLog("An error occured when updating "+upper(tmp[`protocol][0])+" connection, the reason is:"+ex[1])
    }
    if(ex[1]!=NULL){
        throw(ex[1])
    }
}


/*
删除连接,删除连接时会同时清理该连接下的所有订阅及订阅信息
参数：args 为标准json，包含以下字段：
ids: 连接ID  string数组
使用示例：
args = '{"ids":["f88c0d8b-7f53-0f64-3cc3-e79ff6568154","45d4aa2a-5bab-a4d0-27a2-c8131c9f5a0a"]}'
dcp_deleteConnect(args)
*/
def dcp_deleteConnect(args){
    connectArgs = parseExpr(args).eval()
    ex=["user",NULL]
    connectInfo =select * from loadTable("dfs://dataAcquisition","connectInfo") where id in uuid(connectArgs[`ids])
    subIds = select connectId,subId,name as subName from  loadTable("dfs://dataAcquisition","subscribeInfo") where connectId in uuid(connectArgs[`ids])
    tmp = select * from connectInfo left join subIds on connectInfo.id=subIds.connectId  
    mqttInfo = select * from tmp where protocol = `mqtt
    kafkaInfo  = select * from tmp where protocol = `kafka
    try{ 
        for(index in 0..(tmp.size()-1)){
            if(tmp[index].protocol=="mqtt" and tmp[index].subId!=string(NULL)){
                mqtt::unsubscribe(tmp[index].subId)  // 取消订阅
            }else if(tmp[index].protocol=="kafka" and tmp[index].subId!=string(NULL)){
                kafka::cancelSubJob(tmp[index].subId)  // 取消订阅    
            }
        }
        delete from loadTable("dfs://dataAcquisition","subscribeInfo") where connectId in uuid(connectArgs[`ids])
        delete from loadTable("dfs://dataAcquisition","connectInfo") where id in uuid(connectArgs[`ids])
        if(mqttInfo.size()!=0){
            writeLog("The MQTT subscribe ["+concat(mqttInfo[`subName],",")+"] successfully calceled")
            writeLog("The MQTT connection named [" + concat(distinct(mqttInfo[`name]),",")+"] successfully deleted")
        }
        if(kafkaInfo.size()!=0){
            writeLog("The KAFKA subscribe ["+concat(kafkaInfo[`subName],",")+"] successfully calceled")
            writeLog("The KAFKA connection named [" + concat(distinct(kafkaInfo[`name]),",")+"] successfully deleted")
        }
        return '{"status":1}'
    }catch(ex){
        writeLog("An error occured when deleting "+upper(tmp[index].protocol)+" connection "+tmp[index].name+", the reason is:"+ex[1])
    }
    if(ex[1]!=NULL){
        throw(ex[1])
    }
}

/*
获取连接列表  
@args 无
@return 连接列表json,{"mqtt": [], "kafka": []}
*/
def dcp_getConnectList(){
    connectAll = select * from loadTable("dfs://dataAcquisition","connectInfo") order by updateTime desc
    protocolList = exec distinct protocol from connectAll
    res = '{'
    for(index in 0..(protocolList.size()-1)){
        tmp = select * from connectAll where protocol = protocolList[index]
        res +='"'+protocolList[index]+'":'+toStdJson(tmp)
        if(index == protocolList.size()-1){
            res +='}'        
        }else{
            res +=','        
        }
    }
    return res
}


//返回kafka消費者參數列表
def dcp_getKafkaConsumerCfgList(){
    consumerCfgList = '["builtin.features","client.id","metadata.broker.list","bootstrap.servers","message.max.bytes","message.copy.max.bytes",
    "receive.message.max.bytes","max.in.flight.requests.per.connection","max.in.flight","topic.metadata.refresh.interval.ms","metadata.max.age.ms",
    "topic.metadata.refresh.fast.interval.ms","topic.metadata.refresh.fast.cnt","topic.metadata.refresh.sparse","topic.metadata.propagation.max.ms",
    "topic.blacklist","debug","socket.timeout.ms","socket.blocking.max.ms","socket.send.buffer.bytes","socket.receive.buffer.bytes","socket.keepalive.enable",
    "socket.nagle.disable","socket.max.fails","broker.address.ttl","broker.address.family","socket.connection.setup.timeout.ms","connections.max.idle.ms",
    "reconnect.backoff.jitter.ms","reconnect.backoff.ms","reconnect.backoff.max.ms","statistics.interval.ms","enabled_events","error_cb","throttle_cb",
    "stats_cb","log_cb","log_level","log.queue","log.thread.name","enable.random.seed","log.connection.close","background_event_cb","socket_cb","connect_cb",
    "closesocket_cb","open_cb","resolve_cb","opaque","default_topic_conf","internal.termination.signal","api.version.request","api.version.request.timeout.ms",
    "api.version.fallback.ms","broker.version.fallback","allow.auto.create.topics","security.protocol","ssl.cipher.suites","ssl.curves.list","ssl.sigalgs.list",
    "ssl.key.location","ssl.key.password","ssl.key.pem","ssl_key","ssl.certificate.location","ssl.certificate.pem","ssl_certificate","ssl.ca.location",
    "ssl.ca.pem","ssl_ca","ssl.ca.certificate.stores","ssl.crl.location","ssl.keystore.location","ssl.keystore.password","ssl.providers","ssl.engine.location",
    "ssl.engine.id","ssl_engine_callback_data","enable.ssl.certificate.verification","ssl.endpoint.identification.algorithm","ssl.certificate.verify_cb",
    "sasl.mechanisms","sasl.mechanism","sasl.kerberos.service.name","sasl.kerberos.principal","sasl.kerberos.kinit.cmd","sasl.kerberos.keytab",
    "sasl.kerberos.min.time.before.relogin","sasl.username","sasl.password","sasl.oauthbearer.config","enable.sasl.oauthbearer.unsecure.jwt",
    "oauthbearer_token_refresh_cb","sasl.oauthbearer.method","sasl.oauthbearer.client.id","sasl.oauthbearer.client.secret","sasl.oauthbearer.scope",
    "sasl.oauthbearer.extensions","sasl.oauthbearer.token.endpoint.url","plugin.library.paths","interceptors","group.id","group.instance.id",
    "partition.assignment.strategy","session.timeout.ms","heartbeat.interval.ms","group.protocol.type","group.protocol","group.remote.assignor",
    "coordinator.query.interval.ms","max.poll.interval.ms","enable.auto.commit","auto.commit.interval.ms","enable.auto.offset.store","queued.min.messages",
    "queued.max.messages.kbytes","fetch.wait.max.ms","fetch.queue.backoff.ms","fetch.message.max.bytes","max.partition.fetch.bytes","fetch.max.bytes",
    "fetch.min.bytes","fetch.error.backoff.ms","offset.store.method","isolation.level","consume_cb","rebalance_cb","offset_commit_cb","enable.partition.eof",
    "check.crcs","client.rack","transactional.id","transaction.timeout.ms","enable.idempotence","enable.gapless.guarantee","queue.buffering.max.messages",
    "queue.buffering.max.kbytes","queue.buffering.max.ms","linger.ms","message.send.max.retries","retries","retry.backoff.ms","retry.backoff.max.ms",
    "queue.buffering.backpressure.threshold","compression.codec","compression.type","batch.num.messages","batch.size","delivery.report.only.error","dr_cb",
    "dr_msg_cb","sticky.partitioning.linger.ms","client.dns.lookup","request.required.acks","acks","request.timeout.ms","message.timeout.ms",
    "delivery.timeout.ms","queuing.strategy","produce.offset.report","partitioner","partitioner_cb","msg_order_cmp","opaque","compression.codec",
    "compression.type","compression.level","auto.commit.enable","enable.auto.commit","auto.commit.interval.ms","auto.offset.reset","offset.store.path",
    "offset.store.sync.interval.ms","offset.store.method","consume.callback.max.messages"]'
    return '{"consumerCfgList":' + consumerCfgList + '}'    
}

/*
添加订阅信息：
参数：args 为标准json，需要包含以下字段：
commonParams:
name: 订阅名称                    字符串
topic: 订阅主题                   字符串
connectId：使用的连接             字符串
handlerId：使用的解析模板         字符串（parseJson为false时不需要该参数） 
templateParams: 模板参数          字符串
parseJson: 是否解析json数据        bool  
mqttParams:
recvbufSize：接收缓冲区大小       整数（默认20480）
kafkaParams:
partition: 分区                    整数（默认为NULL）
offset: 偏移量                     整数（默认为NULL）
consumerCfg：kafka消费配置         字符串   
使用示例：
args = '{"name":"test","topic":"topic1","parseJson":false,
"templateParams":\'[{\"key\":\"outputTableName\",\"value\":\"dcp_test\"}]\',"connectId":"f88c0d8b-7f53-0f64-3cc3-e79ff6568154"}'
dcp_addSubscribe(args)
args = '{"name":"test","topic":"topic1","parseJson":false,
"templateParams":\'[{\"key\":\"outputTableName\",\"value\":\"dcp_test1\"}]\',
"consumerCfg":\'[{\"key\":\"group.id\",\"value\":\"test\"}]\',
"connectId":"ecffc67c-e6d2-4a72-63cf-386e097016bc"}'
dcp_addSubscribe(args)
*/

def dcp_addSubscribe(args){
    subArgs = parseExpr(args).eval()
    connectInfo = exec protocol,name from loadTable("dfs://dataAcquisition","connectInfo") where id = uuid(subArgs['connectId'])
    proto = connectInfo[`protocol][0]
    connectName = connectInfo[`name][0]
    ex = ["user",NULL]
    try{
        cnt = exec count(*) from loadTable("dfs://dataAcquisition","subscribeInfo") where name = subArgs['name'] and connectId=uuid(subArgs['connectId'])
        if(cnt !=0){
            throw("The "+ upper(proto)+" subscribe name already exists in connection " +connectName+" , please verify the subscribe information")
        }
        id  = rand(uuid(),1)
        subInfo = table(id as id,[uuid(subArgs['connectId'])] as connectId)
        update subInfo set topic = subArgs['topic']
        update subInfo set name = subArgs['name']
        update subInfo set createTime = now()
        update subInfo set updateTime = now()
        update subInfo set subId=string(NULL)
        update subInfo set status=0
        update subInfo set templateParams=subArgs['templateParams']
        update subInfo set parseJson=subArgs['parseJson']
        if(proto=="mqtt"){
            update subInfo set recvbufSize = iif(subArgs['recvbufSize']==string(NULL),20480,subArgs['recvbufSize'])
            update subInfo set consumerCfg = string(NULL)
            update subInfo set partition = int(NULL)
            update subInfo set offset = int(NULL)
        }else if(proto=="kafka"){
            update subInfo set recvbufSize = int(NULL)
            update subInfo set consumerCfg = iif(subArgs['consumerCfg']==string(NULL),string(NULL),subArgs['consumerCfg'])  
            update subInfo set partition = iif(subArgs['partition']==int(NULL),int(NULL),subArgs['partition'])   
            update subInfo set offset = iif(subArgs['offset']==int(NULL),int(NULL),subArgs['offset'])   
        }else{
            throw("the protocol: "+proto + " is not supported ")    
        }   
        if(subArgs[`parseJson]){
            update subInfo set handlerId = uuid(subArgs['handlerId'])
        }
        else{
            handlerId = (exec id from loadTable("dfs://dataAcquisition","ParserTemplate") where comment = "转存json数据" and protocol =  proto )[0]
            update subInfo set handlerId = handlerId
            tableName = parseJsonTable(subArgs['templateParams']).value[0]
            enableTableShareAndPersistence(streamTable(1:0,[`topic,`msg,`ts],[STRING,STRING,TIMESTAMP]),tableName,,,100000,,,100000)
            writeLog("successfuly initialized the default streamTable "+tableName+" for subscribe "+subArgs['name']+" of "+upper(proto)+" connection "+connectName)
        }
        subInfo.reorderColumns!(`id`connectId`topic`partition`offset`name`recvbufSize`handlerId`templateParams`consumerCfg`parseJson`status`subId`createTime`updateTime)
        loadTable("dfs://dataAcquisition","subscribeInfo").append!(subInfo)
        writeLog("The "+ upper(proto) +" connection named " + connectName+" successfully added subscribe "+subArgs['name'])
        return '{"status":1,"id":"'+string(id)[0]+'"}'  
    }catch(ex){
        writeLog("An error occured when adding "+upper(proto)+" subscribe info, the reason is:"+ex[1])
    }
    if(ex[1]!=NULL){
        throw(ex[1])
    }
}


/*
修改订阅
参数：args 为标准json，需要包含以下字段：
commonParam：
id: 订阅ID                  字符串
name：订阅名称               字符串    
topic: 订阅主题              字符串
handlerId：使用的解析模板     字符串
templateParams: 模板参数     修改handlerId,必须同时有templateParams参数
parseJson: 是否解析json数据   bool  
mqttParam:
recvbufSize: 接收缓冲区大小   整数   
kafkaParam:
partition: 分区              整数
offset: 偏移量                整数
consumerCfg: kafka消费配置    字符串    
使用示例:
args = '{"name":"test","topic":"topic1","handlerId":1,"parseJson":false, 
"templateParams":\'[{\"key\":\"outputTableName\",\"value\":\"dcp_test\"}]\',"id":"e7183216-9f11-4d12-b227-4477f9f20313"}'
dcp_updateSubscribe(args)
*/
def dcp_updateSubscribe(args){
    subArgs = parseExpr(args).eval()
    subscribeInfo = select * from loadTable("dfs://dataAcquisition","subscribeInfo") where id=uuid(subArgs[`id])
    connectInfo = exec * from loadTable("dfs://dataAcquisition","connectInfo") where id=uuid(subscribeInfo[`connectId][0])
    proto,connectName,connectId = connectInfo[`protocol][0],connectInfo[`name][0],connectInfo[`id][0]
    ex = ["user",NULL]
    try{
        cnt = exec count(*) from loadTable("dfs://dataAcquisition","subscribeInfo") where name = subArgs['name'] and connectId=uuid(connectId)
        and id != uuid(subArgs['id'])
        if(cnt !=0){
            throw("The "+ upper(proto)+" subscribe name already exists in connection "+connectName+", please verify the subscribe information")
        }
        for(col in subArgs.keys()){
            if(col != "id"){
                if(col !="handlerId"){
                    subscribeInfo[col] = subArgs[col]  
                }else{
                    subscribeInfo[col] = uuid(subArgs[col])
                }
            }
        }
        if(!subArgs[`parseJson]){
            handlerId = (exec id from loadTable("dfs://dataAcquisition","ParserTemplate") where name like "saveJsonMsg%" and protocol =  proto)[0]
            update subscribeInfo set handlerId = handlerId
            tableName = parseJsonTable(subArgs['templateParams']).value[0]
            if(!existsStreamTable(tableName)){
                enableTableShareAndPersistence(streamTable(1:0,[`topic,`msg,`ts],[STRING,STRING,TIMESTAMP]),tableName,,,100000,,,100000)
                writeLog("successfuly initialized the default streamTable "+tableName+" for subscribe "+subArgs['name']+" of "+upper(proto)+" connection "+connectName)
            }
        }
        subscribeInfo[`updateTime] = now()  
        subscribeInfo.reorderColumns!(`id`connectId`topic`partition`offset`name`recvbufSize`handlerId`templateParams`consumerCfg`parseJson`status`subId`createTime`updateTime)  
        delete from loadTable("dfs://dataAcquisition","subscribeInfo") where id=uuid(subArgs[`id])  
        loadTable("dfs://dataAcquisition","subscribeInfo").append!(subscribeInfo)
        if(subArgs[`status]==int(NULL)){
            writeLog("the subscribe "+subArgs['name']+" of "+ upper(proto) +" connection named " + connectName+" successfully updated")
        }
        return '{"status":1}'
    }catch(ex){
        writeLog("An error occured when updating "+upper(proto)+" subscribe info, the reason is:"+ex[1])
    }
    if(ex[1]!=NULL){
        throw(ex[1])
    }
}

/*
删除订阅
参数：args 为标准json，需要包含以下字段：
ids: 订阅ID int数组
dropUseTable:删除订阅时是否删除流表 bool
使用示例：
args = '{"ids":["192c3a31-dee3-b6b3-a3e6-4e08a861df02"],"dropUseTable":true}' 
dcp_deleteSubscribe(args)
*/
def dcp_deleteSubscribe(args){
    subArgs = parseExpr(args).eval()
    subInfo = select * from loadTable("dfs://dataAcquisition","subscribeInfo") where id in uuid(subArgs[`ids])
    connectInfo = select protocol,name from loadTable("dfs://dataAcquisition","connectInfo") where id in subInfo[`connectId]
    proto,connectName = connectInfo[`protocol][0],connectInfo[`name][0]
    ex=["user",NULL]
    try{
        if(subArgs[`dropUseTable]){
            for(i in subInfo.templateParams){//i = templateParams[1]
                t = parseJsonTable(i)
                tbName = t[0].value
                actions = (exec actions from getStreamingStat().pubTables where tableName=tbName)[0]
                if(actions != ""){
                    actions = strReplace(actions,"[","")
                    actions = strReplace(actions,"]","")
                    arr = actions.split(',')
                    for(action in arr){
                        unsubscribeTable(tableName=tbName, actionName=action)
                        sleep(10)
                    }
                }
                if(existsStreamTable(tbName)){
                    dropStreamTable(tbName)
                }
            }
        }
        delete from loadTable("dfs://dataAcquisition","subscribeInfo") where id in uuid(subArgs[`ids])
        writeLog("the subscribe ["+concat(subInfo.name,",")+"] of "+ upper(proto) +" connection named " + connectName+" successfully deleted")
        return '{"status":1}'
    }catch(ex){
        writeLog("An error occured when deleting "+upper(proto)+" subscribe info, the reason is:"+ex[1])
    }
    if(ex[1]!=NULL){
        throw(ex[1])
    }
}



/*
获取订阅列表
参数：args 为标准json，需要包含以下字段：
connectId: 连接ID   整数
*/
def dcp_getConnectAndSubInfo(args){
    subArgs = parseExpr(args).eval()
    connect = select * from loadTable("dfs://dataAcquisition","connectInfo") where id = uuid(subArgs['connectId']) order by updateTime desc
    subscribe = select * from loadTable("dfs://dataAcquisition","subscribeInfo") where connectId = uuid(subArgs['connectId']) order by updateTime desc
    return '{"connectInfo":'+toStdJson(connect[0])+',"subscribes":'+toStdJson(subscribe)+',"total":'+subscribe.size()+'}'      
}


/*
开始订阅
参数：args 为标准json，需要包含以下字段：
subId: 订阅ID   
*/
def dcp_startSubscribe(args){
    subArgs = parseExpr(args).eval()
    //通过订阅id获取链接信息，解析模板信息
    sub = select * from loadTable("dfs://dataAcquisition","subscribeInfo")  where id = uuid(subArgs[`subId])
    connInfo = select * from loadTable("dfs://dataAcquisition","connectInfo")  where id in sub.connectId
    tmp =  (exec * from sub left join connInfo  on connInfo.id=sub.connectId)[0]
    ex=['user',NULL]
    //初始化解析函数
    try{
        handler = (exec handler from loadTable("dfs://dataAcquisition","ParserTemplate") where id = uuid(tmp[`handlerId]))[0]
        runScript(handler)
        //获取解析函数名
        handlerName = handler.split("\n")
        handlerName  = (handlerName[strpos(handlerName,"def")!=-1].split("(")[0].split("def ")[1])[0]
        //拼接订阅脚本，在定义函数时，因为handlerName是动态的，所以无法直接在订阅时指定函数名并执行，需要拼接成字符串后，在调用时通过runScript延迟执行   
        subscribeStr = 
        'sub = select * from loadTable("dfs://dataAcquisition","subscribeInfo")  where id=uuid("'+ subArgs[`subId]+'");
        connInfo = select * from loadTable("dfs://dataAcquisition","connectInfo")  where id in sub.connectId;
        tmp =  (exec * from sub left join connInfo  on connInfo.id=sub.connectId)[0];'
        if(tmp.protocol == "mqtt"){
            //拼接mqtt
            subscribeStr +=  'mqtt::subscribe(tmp["host"],tmp["port"],tmp["topic"],,'+handlerName+'{'
            mqsubArgs = parseExpr(tmp.templateParams).eval() 
            for(i in (0..(mqsubArgs.size()-1))){    
                if(i < mqsubArgs.size()-1 ){
                    subscribeStr += "`"+mqsubArgs[i][`value]+","
                }
                else{
                    subscribeStr += "`"+mqsubArgs[i][`value]
                }
            }
            subscribeStr += '},tmp["username"],tmp["password"],tmp["recvbufSize"]);'
        }
        else if(tmp.protocol == "kafka"){
            //初始化消费者配置
            subscribeStr +='consumerCfg = dict(string, any);
            consumerCfg["metadata.broker.list"] = tmp.host+":"+tmp.port;
            cfgTable = parseJsonTable(tmp.consumerCfg);
            for(i in cfgTable){
                consumerCfg[i.key]=i.value
            }
            consumer = kafka::consumer(consumerCfg);
            topic,partition,offset=[tmp.topic],[tmp.partition],[tmp.offset]; 
            //根据参数选择订阅方式，订阅主题还是分区
            if(partition[0]==int(NULL)){
                kafka::subscribe(consumer, topic);
            }else{
                kafka::assign(consumer, topic, partition, offset)  
            };'
            kasubArgs = parseExpr(tmp.templateParams).eval()
            //第一个解析模板参数必须为表明，根据是否有其他参数，拼接subscribe函数   
            if(kasubArgs.size()==1){
                subscribeStr += 'kafka::createSubJob(consumer,'+kasubArgs[0].value+','+handlerName+',"'+tmp.topic+'");' 
            }else{
                subscribeStr += 'kafka::createSubJob(consumer,'+kasubArgs[0].value+','+handlerName+'{'  
                for(i in (1..(kasubArgs.size()-1))){    
                    if(i < kasubArgs.size()-1 ){
                        subscribeStr += "`"+kasubArgs[i][`value]+","
                    }
                    else{
                        subscribeStr += "`"+kasubArgs[i][`value]
                    }
                }
                subscribeStr += '},"'+tmp.topic+'");'      
            } 
        }   
        runScript(subscribeStr)
        if(tmp.protocol == "mqtt"){
            //获取mqtt订阅ID
            subscriptionId=exec last(subscriptionId) from mqtt::getSubscriberStat() order by createTimestamp
        }else if(tmp.protocol == "kafka"){
            subscriptionId=exec last(subscriptionId) from kafka::getJobStat()  order by createTimestamp
        }   
        writeLog("the subscribe "+tmp.name+" of "+upper(tmp.protocol)+" connection "+tmp.connInfo_name+" successfully started")
        argsNew='{"id":"'+subArgs[`subId]+'","subId":"'+subscriptionId+'","status":1}' 
        dcp_updateSubscribe(argsNew)
    }catch(ex){
        writeLog("An error occured when starting subscribe "+tmp.name+" of "+upper(tmp.protocol)+" connection "+tmp.connInfo_name+" , the reason is:"+ex[1])
    }
    if(ex[1]!=NULL){
        throw(ex[1])
    }
}


/*
停止订阅
参数：args 为标准json，需要包含以下字段：
subId: 订阅ID  string数组 
使用示例：
args = '{"subId":["e7183216-9f11-4d12-b227-4477f9f20313","508dd3c4-1e1d-69c2-2bb2-05a1a2f26c6d"]}'  
dcp_stopSubscribe(args)
*/
def dcp_stopSubscribe(args){
    subArgs = parseExpr(args).eval()
    subId = select id,subId,connectId,name from loadTable("dfs://dataAcquisition","subscribeInfo") where id in uuid(subArgs[`subId])
    connInfo = select id,protocol,name from loadTable("dfs://dataAcquisition","connectInfo") where id in subId.connectId  
    info = select * from subId left join connInfo on connInfo.id=subId.connectId 
    ex=['user',NULL] 
    try{  
        for(i in (0..(subId.size()-1))){  //i=1
            if(info[i].subId != string(NULL)){
                if(info[i].protocol == "mqtt"){
                    mqtt::unsubscribe(info[i].subId)
                }else if(info[i].protocol == "kafka"){
                    kafka::cancelSubJob(info[i].subId)
                }
                writeLog("The subscribe "+info[i].name+" of "+upper(info[i].protocol)+" connection "+info[i].connInfo_name+" successfully stoped")
                argsNew='{"id":"'+string(info[i].id)+'","subId":NULL,"status":0}' 
                dcp_updateSubscribe(argsNew) 
            }   
        }
    }catch(ex){
        writeLog("An error occured when stoping subscribe of "+upper(info[i].protocol)+" connection "+info[i].connInfo_name+" , the reason is:"+ex[1])
    }
    if(ex[1]!=NULL){
        throw(ex[1])
    }
    
}



/*
查看订阅状态
@args subId:订阅ID 字符串
@return 返回一个包含订阅状态的json，键为subStatus   
*/
def dcp_getSubStatus(args){
    subArgs = parseExpr(args).eval()
    subs =select id,subId,connectId from loadTable("dfs://dataAcquisition","subscribeInfo") where id=uuid(subArgs[`subId])
    connInfo = select id,protocol from loadTable("dfs://dataAcquisition","connectInfo") where id = uuid(subs.connectId[0])    
    if(connInfo.protocol == "mqtt"){
        tmp = select * from mqtt::getSubscriberStat() where subscriptionId = subs.subId
    }else if(connInfo.protocol=="kafka"){
        tmp = select * from kafka::getJobStat() where subscriptionId = subs.subId
    }
    return '{"subStatus":'+toStdJson(tmp)+'}'
}


/*
检测订阅状态
将库中状态为开启状态但实际已经不存在的订阅关闭
@args connectId:连接ID int整数  

*/
def dcp_checkSubStatus(args){
    subArgs = parseExpr(args).eval()
    subs =select id,subId,connectId from loadTable("dfs://dataAcquisition","subscribeInfo") where connectId=uuid(subArgs[`connectId])
    connInfo = select id,protocol from loadTable("dfs://dataAcquisition","connectInfo") where id = uuid(subArgs[`connectId])    
    if(connInfo.protocol == "mqtt"){
        nowSub = mqtt::getSubscriberStat().subscriptionId
    }else if(connInfo.protocol=="kafka"){
        nowSub = kafka::getJobStat().subscriptionId
    }
    id = subs.id
    subId = subs.subId  
    if(subId.size() > 0 ){
        for(i in (0..(subId.size()-1))){  //i=0
            if((!(subId[i] in nowSub)) and subId[i]!=string(NULL)){ 
                argsNew='{"id":"'+string(id[i])+'","subId":NULL,"status":0}' 
                dcp_updateSubscribe(argsNew) 
            }
        }
    }
}

/*
解析模板参数
@args 
handler:解析函数的函数体 string
protocol:解析函数对应的协议 string
@return 返回一个参数列表（拼接为字符串）
*/
def dcp_parseTemplateArgs(handler,protocol){
    if(protocol==`mqtt){
        handlerParam = handler.split("){")[0].split("(")[1].split(",")
        handlerParam = handlerParam[0:(handlerParam.size()-2)]    
    }else if(protocol==`kafka){
        handlerParam = handler.split("){")[0].split("(")[1].split(",")
        handlerParam = [`outTableName] <- handlerParam[0:(handlerParam.size()-3)] 
    }
    paramList = '['
    for(index in 0..(handlerParam.size()-1)){   
        if(index < (handlerParam.size()-1)){    
            paramList += '"'+handlerParam[index]+'",'  
        }else{
            paramList += '"'+handlerParam[index]+'"]'
        }
    }
    return paramList   
}

/*
添加模板
@args 
name:模板名称 字符串
handler:函数定义 字符串
protocol:模板协议 字符串
comment:模板备注 字符串
@return 无
*/
def dcp_addHandler(args){
    handlerArgs = parseExpr(args).eval() 
    ex=['user',NULL]
    try{
        id = rand(uuid(),1)
        templateParams = dcp_parseTemplateArgs(handlerArgs[`handler],handlerArgs['protocol'])
        tmp = table(id as id, [handlerArgs['name']] as name, [handlerArgs[`handler]] as handler, [handlerArgs['protocol']] as `protocol,
        string([handlerArgs['comment']]) as comment,[templateParams] as templateParams,[now()] as createTime,[now()] as updateTime)  
        loadTable("dfs://dataAcquisition","ParserTemplate").append!(tmp)
        writeLog("The "+upper(handlerArgs[`protocol])+ " handler "+handlerArgs[`name]+" successfully added")
        return '{"status":1,"id":"'+string(id[0])+'"}'   
    }catch(ex){
        writeLog("An error occured when adding The "+upper(handlerArgs[`protocol])+ " handler "+handlerArgs[`name]+", the reason is:"+ex[1])
    } 
    if(ex[1]!=NULL){
        throw(ex[1])
    }
}

/*
修改模板
@args 
必选：
id:模板id 整数
可选：
name:模板名称 字符串
protocol:协议 字符串
handler:函数定义 字符串
comment:模板备注 字符串
@return 无
*/
def dcp_updateHandler(args){  
    handlerArgs = parseExpr(args).eval()    
    ex=['user',NULL]
    try{
        ParserTemplate = select * from loadTable("dfs://dataAcquisition","ParserTemplate") where id=uuid(handlerArgs[`id])
        update ParserTemplate set name = handlerArgs[`name] 
        update ParserTemplate set protocol = handlerArgs[`protocol] 
        update ParserTemplate set handler = handlerArgs[`handler] 
        update ParserTemplate set comment = handlerArgs[`comment] 
        update ParserTemplate set updateTime = now() 
        delete from loadTable("dfs://dataAcquisition","ParserTemplate") where id=uuid(handlerArgs[`id])
        loadTable("dfs://dataAcquisition","ParserTemplate").append!(ParserTemplate)
        writeLog("The "+upper(handlerArgs[`protocol])+ " handler "+handlerArgs[`name]+" successfully updated")
        return '{"status":1}'   //更新成功  
    }catch(ex){
        writeLog("An error occured when updating The "+upper(handlerArgs[`protocol])+ " handler "+handlerArgs[`name]+", the reason is:"+ex[1])
    }
    if(ex[1]!=NULL){
        throw(ex[1])
    }
}    


/*
删除模板
@args 
ids:模板id string数组
args = '{"ids":[]}'
*/
def dcp_deleteHandler(args){
    handlerArgs = parseExpr(args).eval()
    handlerInfo = select * from loadTable("dfs://dataAcquisition","ParserTemplate") where id in uuid(handlerArgs[`ids])
    mqttInfo = 
    ex=['user',NULL]
    try{
        delete from loadTable("dfs://dataAcquisition","ParserTemplate") where id in uuid(handlerArgs[`ids])
        writeLog("The handler "+handlerArgs[`name]+" successfully deleted")
        return '{"status":1}'   //删除成功  
    }catch(ex){
        writeLog("An error occured when deleting the handler "+handlerArgs[`name]+", the reason is:"+ex[1])
    }
    if(ex[1]!=NULL){
        throw(ex[1])
    }
}



/*s
获取点位解析模板列表
@args "protocol":解析模板协议 字符串(默认为空)
@return 返回一个包含解析模板信息的json，键为items，值为解析模板列表 
*/  
def dcp_getParserTemplateList(args="{}"){
    protocolType=parseExpr(args).eval()['protocol']
    if(protocolType==string(NULL)){
        tmp = select * from loadTable("dfs://dataAcquisition","ParserTemplate") order by updateTime desc    
    }else{
        tmp = select * from loadTable("dfs://dataAcquisition","ParserTemplate") where protocol=protocolType order by updateTime desc
    } 
    return '{"items":'+toStdJson(tmp)+',"total":'+tmp.size()+'}'  
}

/*
获取模板参数
@args handlerId:模板ID int整数
@return 返回一个包含模板参数的json，键为returnArgs，值为参数列表   
*/
def dcp_getTemplateArgs(args){
    handlerArgs = parseExpr(args).eval()
    handler = (exec templateParams from loadTable("dfs://dataAcquisition","ParserTemplate") where id = uuid(handlerArgs['handlerId']))[0]
    return '{"returnArgs":'+handler+'}'    
}


//初始化解析模板
def initParserTemplate(){   
    //初始化解析模板
    handler = '
    def msgHandler(outputTableName,timeColumn,idColumn,topic,message){
        tempdict = parseExpr(message).eval()
        keys = tempdict.keys()
        if(timeColumn==NULL){
            ts = now()
        }else{
            ts = temporalParse(tempdict[timeColumn],"yyyy-MM-dd HH:mm:ss")
        }
        id = tempdict[idColumn] 
        for(i in keys){
            if(!(i in [timeColumn,idColumn] )){
                tmp = table([ts] as ts,[id] as id,[i] as metric,[tempdict[i]] as value)
                objByName(outputTableName).append!(tmp)            
            }
        }
    }
    '
    args = '{"name":"parseMqtt","handler":\''+handler+'\',"protocol":"mqtt","comment":"测试解析模板"}'   
    dcp_addHandler(args)


    handler = "
    def saveJsonMsg(outputTableName,topic,msg){
        objByName(outputTableName).append!(table([topic]as topic,[msg] as msg,[now()] as ts))
    }
    "
    args = '{"name":"saveJsonMsg","handler":\''+handler+'\',"protocol":"mqtt","comment":"转存json数据"}'   
    dcp_addHandler(args)

    handler = "
    def saveMsg(msg,key,topic){
        return table([topic] as topic,[msg] as dataContent,[now(true)] as startTime)    
    }
    "
    args = '{"name":"saveJsonMsg_kafka","handler":\''+handler+'\',"protocol":"kafka","comment":"转存json数据"}'   
    dcp_addHandler(args)


    handler='
     def parseKafka(timeColumn,idColumn,msg,key,topic){
        tempdict = parseExpr(msg).eval()
        writeLog("KAFKA DATA:"+msg)
        keys = tempdict.keys()
        rowNum = keys.size()-2
        tmp = table(rowNum:rowNum,[`ts,`id,`metric,`value],[TIMESTAMP,STRING,STRING,DOUBLE])    
        if(timeColumn==NULL or tempdict[timeColumn]==NULL){ 
            ts = now()
        }else{
            ts = temporalParse(tempdict[timeColumn],"yyyy.MM.ddTHH:mm:ss.SSS")
        }
        tmp[`ts] = ts
        tmp[`id] = tempdict[idColumn] 
        for(i in keys){
            if(!(i in [timeColumn,idColumn] )){
                tmp[`metric] =  take(i,rowNum) 
                tmp[`value] =   tempdict[i]
            }
        }
        return tmp  
    }'
    args = '{"name":"parseKafka","handler":\''+handler+'\',"protocol":"kafka","comment":"解析kafka json数据"}'   
    dcp_addHandler(args)

}

/*
获取调试日志
@args 标准json，需要包含以下字段：
protocol 协议 字符串
@return 最近一小时与mqtt相关的日志，字符串向量
*/
def dcp_getLog(args){
    protocol = upper(parseExpr(args).eval()[`protocol])
    rowBytes = 5000000
    log = getServerLog(rowBytes,getServerLogLength(getNodeAlias())-rowBytes,true,getNodeAlias()) as log
    res = log[regexFind(log,protocol)!=-1]
    return reverse(res)
}

/*
初始化检测函数
@args null
@return 返回一个json，键为status，值为0或1，表示是否初始化完成  
*/
def dcp_exitsDataAcquisition(){
    if(existsDatabase("dfs://dataAcquisition")){
        return '{"status":1,"message":"初始化已完成"}'
    }else{
        return '{"status":0,"message":"还未初始化库表及函数视图"}'
    }   
}


def dcp_createAllTable(){
    db = database("dfs://dataAcquisition",VALUE,[`1])
    colNames = `id`name`protocol`host`port`username`password`createTime`updateTime
    colTypes = [UUID,STRING,STRING,STRING,INT,STRING,STRING,TIMESTAMP,TIMESTAMP]
    createTable(db,table(1:0,colNames,colTypes),`connectInfo)

    colNames = `id`connectId`topic`partition`offset`name`recvbufSize`handlerId`templateParams`consumerCfg`parseJson`status`subId`createTime`updateTime  
    colTypes = [UUID,UUID,STRING,INT,INT,STRING,INT,UUID,STRING,STRING,BOOL,INT,STRING,TIMESTAMP,TIMESTAMP]
    createTable(database("dfs://dataAcquisition"),table(1:0,colNames,colTypes),`subscribeInfo)  

    colNames = `id`name`handler`protocol`comment`templateParams`createTime`updateTime
    colTypes=[UUID,STRING,STRING,STRING,STRING,STRING,TIMESTAMP,TIMESTAMP]
    createTable(database("dfs://dataAcquisition"),table(1:0,colNames,colTypes),`ParserTemplate)
}


def dcp_stopAllSub(){
    ids = exec subscriptionId from mqtt::getSubscriberStat()
    for(id in ids){
        mqtt::unsubscribe(id)    
    }
}

def dcp_dropAllFunctionView(){
    dropFunctionView(`dcp_addConnect)
    dropFunctionView(`dcp_updateConnect)
    dropFunctionView(`dcp_deleteConnect)
    dropFunctionView(`dcp_addSubscribe)
    dropFunctionView(`dcp_updateSubscribe)
    dropFunctionView(`dcp_deleteSubscribe)
    dropFunctionView(`dcp_startSubscribe)
    dropFunctionView(`dcp_stopSubscribe) 
    dropFunctionView(`dcp_getConnectList) 
    dropFunctionView(`dcp_getConnectAndSubInfo) 
    dropFunctionView(`dcp_getParserTemplateList)
    dropFunctionView(`dcp_parseTemplateArgs) 
    dropFunctionView(`dcp_addHandler)
    dropFunctionView(`dcp_updateHandler)
    dropFunctionView(`dcp_deleteHandler)
    dropFunctionView(`dcp_getLog)
    dropFunctionView(`dcp_checkSubStatus)
    dropFunctionView(`dcp_getSubStatus)
}

def dcp_clearEnv(){
    dcp_stopAllSub()
    dcp_dropAllFunctionView()
    dropDatabase("dfs://dataAcquisition")
}



def dcp_init(){
    dcp_createAllTable()
    initParserTemplate()
    addFunctionView(dcp_addConnect)
    addFunctionView(dcp_updateConnect)
    addFunctionView(dcp_deleteConnect)
    addFunctionView(dcp_addSubscribe)
    addFunctionView(dcp_updateSubscribe)
    addFunctionView(dcp_deleteSubscribe)
    addFunctionView(dcp_startSubscribe)
    addFunctionView(dcp_stopSubscribe)
    addFunctionView(dcp_getConnectList)
    addFunctionView(dcp_getConnectAndSubInfo)
    addFunctionView(dcp_getParserTemplateList)
    addFunctionView(dcp_parseTemplateArgs)
    addFunctionView(dcp_addHandler)
    addFunctionView(dcp_updateHandler)
    addFunctionView(dcp_deleteHandler)
    addFunctionView(dcp_getLog)
    addFunctionView(dcp_checkSubStatus)
    addFunctionView(dcp_getSubStatus)
}
