// drop database if exists "dfs://autoInspection"

def mostQueriedDFSTables(params) {
    if (!bool(getConfig("enableDFSQueryLog"))) {
        return (false, "未配置 enableDFSQueryLog=true。", "请配置 enableDFSQueryLog=true 以支持该项检查。")
    }
    
    startTime_ = params["startTime"]
    endTime_ = params["endTime"]
    queryCountThreshold = params["queryCountThreshold"]
    
    getQueryLogInner = def(startTime_, endTime_) {
		logDir = getConfig("logFile").split("/")
		logDir = logDir[:(logDir.size()-1)].concat("/")
        if (isNull(logDir)) {
            logDir = "./"
        }
        logFiles = files(logDir, "%_query.log")
        schema = table(
            ["node","userId","sessionId","jobId","rootId","type","level","time","database","table","jobDesc"] as name,
            ["STRING", "STRING", "LONG", "UUID", "UUID", "STRING", "INT", "NANOTIMESTAMP", "STRING", "STRING", "STRING"] as type
        )
		if (logFiles.size() == 0) {
			throw "Error: no query log found in " + logDir + ", maybe you haven\'t run any sql yet."
		}
        addColumn(logFiles, `startTime`endTime, [TIMESTAMP, TIMESTAMP])
        update logFiles set endTime = temporalParse(substr(filename, 0, 14), "yyyyMMddHHmmss")
        update logFiles set startTime = move(endTime, 1)
        if (!isNull(startTime_)) {
            delete from logFiles where endTime != NULL and endTime < startTime_
        }
        if (!isNull(endTime_)) {
            delete from logFiles where startTime != NULL and startTime > endTime_
        }
        
        ret = table(1:0, `database`table`count, [STRING, STRING, LONG])
        for (filename in logFiles["filename"]) {
            filePath = logDir + "/" + filename
            logs = loadText(filePath, schema=schema)
            if (!isNull(startTime_)) {
                logs = select * from logs where time >= nanotimestamp(startTime_)
            }
            if (!isNull(endTime_)) {
                logs = select * from logs where time <= nanotimestamp(endTime_)
            }
            delete from logs where database == NULL
            res = select count(*) as count from logs group by database, table order by count desc limit 10
            ret.append!(res)
        }
		return ret
	}
    nodes = exec name from rpc(getControllerAlias(), getClusterPerf) where mode != 1 and mode != 2
    ret = pnodeRun(getQueryLogInner{startTime_, endTime_}, nodes) 
    ret = select sum(count) as count from ret group by database, table order by count desc limit 10
    
    if (!isVoid(queryCountThreshold) && !isNull(queryCountThreshold)) {  
        highFrequencyTables = select * from ret where count > queryCountThreshold  
        if (highFrequencyTables.size() > 0) {  
            errorMsg = "发现 " + snippet(highFrequencyTables.size()) + " 个库表访问次数超过阈值 " + snippet(queryCountThreshold) + " 次"  
            tableInfo = exec (database + "." + table + " (" + string(count) + " 次)") from highFrequencyTables  
            return (false, errorMsg, "库表访问次数超过阈值的库表有：" + tableInfo.concat("\n"))  
        }  
    }

	return (true, ret, NULL)
}


// 测试返回true（阈值较大）  
params1 = dict(STRING, ANY)  
params1["startTime"] = temporalAdd(now(), -1, "d")  
params1["endTime"] = now()  
params1["queryCountThreshold"] = 10000  // 10000次  
result1 = mostQueriedDFSTables(params1)  
print(result1[0])  // true
print(result1[1])  // true
  
// 测试返回false（阈值较小）  
params2 = dict(STRING, ANY)  
params2["startTime"] = temporalAdd(now(), -1, "d")  
params2["endTime"] = now()  
params2["queryCountThreshold"] = 50  // 50次  
result2 = mostQueriedDFSTables(params2)
print(result2[0])  // false
print(result2[1])  // 发现 1 个库表访问次数超过阈值 50 次




