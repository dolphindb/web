if (!existsDatabase("dfs://autoInspection")) {
    clearEnv()
    initDfs()
}
go

// ------------- group 0 ------------------
name = "nodeStatus"
displayName = "节点状态"
group = "0"
desc = "检查所有节点是否在线。"
nodes = NULL // NULL 指该指标不能指定节点运行，选择任一数据节点执行
params = NULL // NULL 指无参数
script = '
def nodeStatus(params) {
    nodes = select * from rpc(getControllerAlias(), getClusterPerf) where state != 1
    if (nodes.size() > 0) {
        detail = nodes["name"].concat(",") + " 节点下线"
        suggestion = "查看节点日志以排查节点下线原因，参考《节点宕机》官方文档。"
        return (false, detail, suggestion)
    }
    return (true, NULL, NULL)
}
'
newMetric(name, displayName, group, desc, nodes, script, params)

name = "licenseExpiration"
displayName = "license 有效期"
group = "0"
desc = "检查所有节点 license 有效期。"
nodes = NULL
script = '
def licenseExpiration(params=NULL) {
    runScript("use ops; res = select * from getAllLicenses()")
    res = objByName("res")
    cnt = exec count(*) from res where temporalAdd(end_date, -7d) <= today()
    res = select node as "节点名", end_date as "到期时间" from res
    if (cnt > 0) {
        return (false, res, "请及时更新 license 文件。")
    }
    return (true, res, NULL)
}
'
newMetric(name, displayName, group, desc, nodes, script)
go

name = "connectionNum"
displayName = "外部连接数"
group = "0"
desc = "检查指定节点的外部连接数是否超过 maxConnections 配置值的 90%。"
nodes = [0, 2, 3, 4]
script = '
def connectionNum(params) {
    connectionNum = int(getPerf()["connectionNum"])
    maxConnectionNum = int(getConfig("maxConnections"))
    
    if (connectionNum >= int(maxConnectionNum * 0.9)) {
        return (false, "外部连接数: " + string(connectionNum) + " 大于等于 maxConnections 配置值: " + string(maxConnectionNum) + " * 90%", "请使用 getCurrentSessionAndUser 方法检查所有会话并使用 closeSessions 方法适当关闭连接。")
    }
    
    return (true, "外部连接数: " + string(connectionNum) + " 小于 maxConnections 配置值: " + string(maxConnectionNum) + " * 90%", NULL)
}
'
newMetric(name, displayName, group, desc, nodes, script)
go

name = "nodeVersion"
displayName = "节点版本一致"
group = "0"
desc = "检查各个节点版本是否一致。"
nodes = NULL
script = '
def nodeVersion(params) {
    nodes = exec name from rpc(getControllerAlias(), getClusterPerf{true}) where mode != 1
    ver = pnodeRun(version, nodes)
    insert into ver values (getControllerAlias(), rpc(getControllerAlias(), version))
    cnt = select distinct(value) from ver
    if (cnt.size() > 1) {
        return (false, "存在节点版本不一致：", "请升级 DolphinDB 使所有节点版本一致。", ver)
    }
    return (true, version(), NULL)
}
'
newMetric(name, displayName, group, desc, nodes, script)
go

name = "pluginVersion"
displayName = "插件版本与集群版本一致"
group = "0"
desc = "检查集群版本与插件版本是否一致。"
nodes = NULL
script = '
def pluginVersion(params) {
    listPluginsInner = def() {
        pluginDir = getPluginDir()
        pluginNames = exec filename from files(pluginDir) where isDir = true
        ret = table(1:0, `pluginName`version, [STRING, STRING])
        for (pluginName in pluginNames) {
            // pluginName = pluginNames[0]
            dir = pluginDir + "/" + pluginName
            pattern = "Plugin" + upper(pluginName[0]) + pluginName[1:] + ".txt"
            txtName = exec first(filename) from files(dir, "%.txt") where filename ilike pattern
            if (txtName.strlen() == 0) {
                continue
            }
            f = file(dir + "/" + txtName)
            line = readLine(f)
            s = line.split(",")
            if (s.size() < 3) {
                continue
            }
            pluginName = s.first()
            pluginVersion = s.last()
            tableInsert(ret, (pluginName, pluginVersion))
        }
        return ret
    }
    
    nodes = exec name from rpc(getControllerAlias(), getClusterPerf{true}) where mode != 1
    info = pnodeRun(listPluginsInner)
    cnt = exec count(*) from rpc(getControllerAlias(), getClusterPerf) where mode == 3
    if (cnt == 0) {
        info_ = rpc(getControllerAlias(), listPluginsInner)
        update info_ set node = getControllerAlias()
        info.append!(info_)
    }
    
    ddbVersion = version().split(" ").first()
    ddbVersion_ = ddbVersion.split(".")
    err = select * from info limit 0
    for (item in info) {
        pluginVersion = item["version"].split(".")
        for (i in 0..2) {
            if (ddbVersion_[i] != pluginVersion[i]) {
                tableInsert(err, item)
                break
            }
        }
    }
    
    if (err.size() > 0) {
        return (false, err, "请升级插件至与 DolphinDB 版本的前3位一致，DolphinDB 版本：" + string(version()))
    }
    
    return (true, NULL, NULL)
}
'
version = 1
newMetric(name, displayName, group, desc, nodes, script, NULL, version)
go

// -------------------------- group 1 ------------------------------
name = "recoveryStatus"
displayName = "恢复事务状态"
group = "1"
desc = "检查恢复事务状态是否正常，以及是否在指定时间内推进。
参数说明：
- checkInterval: 正整数，检查时间间隔，单位 ms，默认 10000 ms。"
nodes = NULL // NULL 指该指标不能指定节点运行，选择任一数据节点执行
script = '
def recoveryStatus(mutable params){
    failureTask=select * from rpc(getControllerAlias(),getRecoveryTaskStatus) where FailureReason == "Aborted";
    if(failureTask.size()>0){
        return false,failureTask.size()+" 个副本恢复任务执行失败。","调用 getRecoveryTaskStatus 方法排查错误原因。";
    }
    prevInProcessTask=select * from rpc(getControllerAlias(),getRecoveryTaskStatus) where Status=="In-Progress";

    if(prevInProcessTask.size() == 0){
        return (true, NULL, NULL)
    }

    checkInterval = iif(isVoid(params["checkInterval"]), 10000, int(params["checkInterval"]))
    sleep(checkInterval)
    
    inProcessTask=select * from rpc(getControllerAlias(),getRecoveryTaskStatus) where Status=="In-Progress";
    if(prevInProcessTask.size()>0&&inProcessTask.size()>0){
        existTask=set(prevInProcessTask.TaskId)-set(inProcessTask.TaskId);
        if(existTask.size()==prevInProcessTask.size()){
            return false,prevInProcessTask.size()+"个副本恢复任务在 " + checkInterval + "ms 时间内一直没有推进或推进非常缓慢。","调用 getRecoveryTaskStatus 方法排查卡住原因。";
        }
    }
    return true,NULL,NULL;
}
'
params = [
    dict(`name`type, ["checkInterval", "INT"])
]
newMetric(name, displayName, group, desc, nodes, script, params)
go

name = "diskUsage"
displayName = "存储空间"
group = "1"
desc = "检查数据节点总存储空间是否超过 volumeUsageThreshold 配置值。"
nodes = [0]
script = '
def diskUsage(params) {
    diskUsage = 1 - getPerf().diskFreeSpaceRatio
    threshold = double(rpc(getControllerAlias(), getConfig{"volumeUsageThreshold"}))
    roundDiskUsage = round(diskUsage*100, 2)
    if (diskUsage >= threshold) {
        detail = "磁盘使用率 " + roundDiskUsage.format("0.00") + "% 大于等于 volumeUsageThreshold 配置项 " + round(threshold*100, 2) + "%。"
        suggestion = "1. 在服务器上确认 DolphinDB 或其他程序是否占用过多存储空间；
2. 删除部分表数据以腾出空间；
3. 扩容硬盘。"
        return (false, detail, suggestion)
    }
    return (true, "磁盘使用率 " + roundDiskUsage.format("0.00") + "% 小于 volumeUsageThreshold 配置项 " + round(threshold*100, 2) + "%。", NULL)
}
'
newMetric(name, displayName, group, desc, nodes, script)
go

name = "memUsage"
displayName = "内存占用"
group = "1"
desc = "检查节点内存占用是否超过 maxMemSize 配置值 * 90%。"
nodes = [0, 2, 3, 4]
script = '
def memUsage(params) {
    maxMemSize = int(getConfig("maxMemSize"))
    allocatedGB = mem()["allocatedBytes"] \\ 1024 \\ 1024 \\ 1024
    if (allocatedGB >= maxMemSize * 0.9) {
        throw (false, "节点已分配内存 " + allocatedGB.format("0.000") + " GB 大于等于最大内存 " + maxMemSize + " GB * 90%", "参照《内存管理》官方文档排查内存占用情况。")
    }
    return (true, NULL, NULL)
}
'
newMetric(name, displayName, group, desc, nodes, script)
go

name = "levelFileIndexCacheStatus"
displayName = "TSDB 索引内存占用"
group = "1"
desc = "检查数据节点 TSDB 索引内存占用是否超过 TSDBLevelFileIndexCacheSize 配置值 * 90%。"
nodes = [0]
script = '
def levelFileIndexCacheStatus(params) {
    res = getLevelFileIndexCacheStatus()
    if (res["usage"] > res["capacity"] * 0.9) {
        throw (false, "level file 索引使用的内存 " + res["usage"] + " 字节大于上限 " + res["capacity"] + " 字节 * 90%", "调大 TSDBLevelFileIndexCacheSize 配置值。")
    }
    return (true, NULL, NULL)
}
'
newMetric(name, displayName, group, desc, nodes, script)
go

name = "chunksStatus"
displayName = "元数据状态"
group = "1"
desc = "检查元数据状态。"
nodes = NULL
script = '
def chunksStatus(params) {
    masterMeta = select * from rpc(getControllerAlias(), getClusterChunksStatus) where state != "COMPLETE" and lastUpdated - now() > 60*60*1000
    if (masterMeta.size() > 0) {
        return (false, "控制节点存在 " + string(masterMeta.size()) + " 条元数据状态异常超过1小时，部分统计结果如下：", "请参考官方教程《分区状态不一致》排查问题。", select * from masterMeta limit 10)
    }
    
    return (true, NULL, NULL)
}
'
newMetric(name, displayName, group, desc, nodes, script)
go

name = "chunksVersion"
displayName = "元数据版本"
group = "1"
desc = "检查元数据版本。"
nodes = NULL
script = '
def chunksVersion(params) {
    threshold = 10 // 事务进行中出现少量版本不一致为正常现象
    masterMeta = rpc(getControllerAlias(), getClusterChunksStatus)
    nodes = exec name from rpc(getControllerAlias(), getClusterPerf) where mode == 0 or mode == 3
    chunkMeta = pnodeRun(getAllChunks, nodes)
    allNotEqual=select masterMeta.chunkId as masterChunkId, masterMeta.version as masterVersion, chunkMeta.chunkId as datanodeChunkId, chunkMeta.version as datanodeVersion from fj(masterMeta, chunkMeta, `chunkId) where chunkMeta.version != masterMeta.version 
    detail = ""
    if (allNotEqual.size() > threshold) {
        return (false, "控制节点存在元数据与数据节点元数据版本不一致: " + string(allNotEqual.size()) + " 条，部分统计结果如下：", "请参考官方教程《分区状态不一致》排查问题。", select top 10 * from allNotEqual)
    }
    chunkNotEqual=select * from chunkMeta context by chunkId having nunique(version)>1
    if (chunkNotEqual.size() > threshold) {
        return (false, "数据节点存在相同副本元数据版本不一致: " + string(chunkNotEqual.size()) + " 条。", "请参考官方教程《分区状态不一致》排查问题。", select top 10 * from chunkNotEqual)
    }
    
    return (true, NULL, NULL)
}
'
newMetric(name, displayName, group, desc, nodes, script)
go

name = "chunksCid"
displayName = "元数据 cid"
group = "1"
desc = "检查元数据 cid。"
nodes = NULL
script = '
def chunksCid(params) {
    masterMeta = select * from rpc(getControllerAlias(), getClusterChunksStatus) where state == "COMPLETE" // 只查询状态完成的元数据，因为事务中的元数据 cid 会不一致
    update masterMeta set cid = versionChain.split(":").at(0).long()
    nodes = exec name from rpc(getControllerAlias(), getClusterPerf) where mode == 0 or mode == 3
    chunkMeta = select * from pnodeRun(getAllChunks, nodes) where state == 0
    addColumn(chunkMeta, "cid", LONG)
    update chunkMeta set cid = versionList.split(",").at(0).split(":").at(1).long() where !(dfsPath.endsWith("domain") or dfsPath.endsWith(".tbl"))
    update chunkMeta set cid = versionList.split(":").at(0).long() where dfsPath.endsWith("domain") or dfsPath.endsWith(".tbl")
    allNotEqual=select chunkId, masterMeta.file, chunkMeta.dfsPath, masterMeta.versionChain, masterMeta.cid as masterCid, chunkMeta.versionList, chunkMeta.cid as chunkCid from fj(masterMeta, chunkMeta, `chunkId) where masterMeta.cid != chunkMeta.cid 
    if (allNotEqual.size() > 0) {
        return (false, "控制节点存在 " + allNotEqual.size() + " 条元数据与数据节点元数据 cid 不一致，部分统计结果如下：", "请参考官方教程《分区状态不一致》排查问题，删除错误副本并拷贝正确副本恢复。", select top 10 * from allNotEqual)   
    }
    
    return (true, NULL, NULL)
}
'
newMetric(name, displayName, group, desc, nodes, script)
go

name = "replicaNum"
displayName = "副本数"
group = "1"
desc = "检查是否存在副本数小于配置项的副本。"
nodes = NULL
script = '
def replicaNum(params) {
    dfsReplicationFactor = int(getConfig("dfsReplicationFactor"))
    if (isNull(dfsReplicationFactor) or dfsReplicationFactor == 1) { // 单副本没必要检查
        return (true, NULL, NULL)
    }
    
    nodes = exec name from rpc(getControllerAlias(), getClusterPerf) where mode == 0 or mode == 3
    replicaNum = select count(*) as cnt from pnodeRun(getAllChunks) where state == 0 group by chunkId // 只查询状态完成的元数据，因为事务中的元数据可能副本还在构建
    replicaNum = select * from replicaNum where cnt != dfsReplicationFactor
    if (replicaNum.size() > 0) {
        return (false, "存在 " + replicaNum.size() + " 个分区副本数小于 dfsReplicationFactor 配置值 " + dfsReplicationFactor + "，部分统计结果如下：", "请参考官方教程《分区状态不一致》排查问题。", select top 10 * from replicaNum)
    }
    
    return (true, NULL, NULL)
}
'
newMetric(name, displayName, group, desc, nodes, script)
go

name = "replicaRowNum"
displayName = "副本一致"
group = "1"
desc = "检查在指定的 startTime 到 endTime 之间，是否存在副本数据条数不一致，仅统计有写入的副本。
参数说明：
- startTime：TIMESTAMP，统计范围的开始时间，默认值为上次相同方案 ID 的报告的开始时间。
- endTime：TIMESTAMP，统计范围的结束时间，默认值为当前报告的开始时间。"
nodes = NULL
script = '
def getChunkidNode(nodes, replicas, chunkIds){
    replicaArray=replicas.split(",");
    getReplicaArray=def(nodes,chunkId,replicaArray){
        getReplicaChunkidNode=def(nodes,chunkId,replica){
            replicaNode=replica.split(":")[0];
            if(in(replicaNode,nodes)==false){
                return table(1:0,["chunkId","node"],[STRING,STRING]);
            }
            return table(chunkId as chunkId,replicaNode as node);
        }
        return unionAll(loop(getReplicaChunkidNode{nodes,chunkId},replicaArray),false);
    }
    return unionAll(loop(getReplicaArray{nodes},chunkIds,replicaArray),false);
}
def addNodeResult(mutable chunkidNodeRowArray,node,chunkIds){
    getRowNum=def(chunkIds){
        return exec string(chunkId) as chunkId,rowNum from getTabletsMeta(top=-1) where string(chunkId) in chunkIds;
    }
    chunkIdRowNum=rpc(node,getRowNum,chunkIds);
    chunkIdRowNum.update!("node",node);
    chunkidNodeRowArray.append!(chunkIdRowNum);
    return chunkidNodeRowArray.size();
}
def addBadChunkId(mutable badChunkId,chunkId,rowNum){
    badFlag=rowNum[first(rowNum)!=rowNum];
    if(sum(badFlag)<1)
        return 0;
    badChunkId.append!(chunkId);
    return 1;
}
def replicaRowNum(params){
    if(int(getConfig().dfsReplicationFactor)<2){
        return (true, "节点副本数小于 2，无法进行校验。", NULL)
    }
    startTime= params["startTime"]
    endTime= params["endTime"]
    nodes = exec name from rpc(getControllerAlias(), getClusterPerf) where mode==0 or mode==3;
    controllerChunks=select * from rpc(getControllerAlias(),getClusterChunksStatus) where lastUpdated>=startTime and lastUpdated<=endTime;
    if (controllerChunks.chunkId.size() == 0) {
        return (true, NULL, NULL)
    }
    chunkidNode=getChunkidNode(nodes,controllerChunks.replicas,controllerChunks.chunkId);
    chunkidNodeRowArray=array(ANY);
    select addNodeResult(chunkidNodeRowArray,first(node),chunkId) from chunkidNode group by node;
    chunkidNodeRow=unionAll(chunkidNodeRowArray,false);
    badChunkId=array(ANY);
    select addBadChunkId(badChunkId,first(chunkId),rowNum) from chunkidNodeRow group by chunkId;
    if(badChunkId.size()>0){
        badChunkId_ = iif(badChunkId.size()>10, badChunkId[:10], badChunkId)
        return false,"存在 "+badChunkId.size()+" 个不一致的副本。","请使用 deleteReplicas 删除错误副本并使用 copyReplicas 拷贝正确副本恢复。", badChunkId_.concat(", ");
    }
    return true,"所有分区副本数完全一致","";
}
'
params = [
    dict(`name`type, ["startTime", "TIMESTAMP"]),
    dict(`name`type, ["endTime", "TIMESTAMP"])
]
newMetric(name, displayName, group, desc, nodes, script, toStdJson(params))
go

name = "errorLogs"
displayName = "错误日志"
group = "1"
desc = "检查指定时间范围内（startTime 到 endTime）是否存在 ERROR/WARNING 日志。
参数说明：
- startTime：TIMESTAMP，统计范围的开始时间，默认值为上次相同方案 ID 的报告的开始时间。
- endTime：TIMESTAMP，统计范围的结束时间，默认值为当前报告的开始时间。
- logLevel：STRING 数组，统计的日志等级，可取值：ERROR，WARNING。"
nodes = [0, 2, 3, 4]
script = '
def getServerLogEx(startTime, endTime) {
    startTime_ = timestamp(startTime)
    endTime_ = timestamp(endTime)
    logFile = getConfig("logFile")
    s = logFile.split("/")
    logDir = s[:(s.size()-1)].concat("/")
    logDir = iif(isNull(logDir), "./", logDir)
    nodeAlias = getNodeAlias()
    cnt = exec count(*) from rpc(getControllerAlias(), getClusterPerf) where mode == 3
    if (cnt == 1) {
        pattern = "%" + s.last()
    } else {
        pattern = "%" + nodeAlias + ".log"
    }
    logFiles = select * from files(logDir, pattern) where isDir == false order by filename asc
    addColumn(logFiles, `startTime`endTime, [TIMESTAMP, TIMESTAMP])
    update logFiles set endTime = temporalParse(substr(filename, 0, 14), "yyyyMMddHHmmss")
    update logFiles set startTime = move(endTime, 1)
    delete from logFiles where endTime != NULL and endTime < startTime_
    delete from logFiles where startTime != NULL and startTime > endTime_
    errorCnt = 0
    warningCnt = 0
    print(logFiles["filename"])
    for (filename in logFiles["filename"]) {
        print(filename)
        filepath = logDir + "/" + filename
        fin = file(filepath)
        maxByteSize = 1024*1024
        bytes = array(CHAR, maxByteSize)
        lastLine = ""
        do {
            numByte = fin.read!(bytes, 0, maxByteSize)
            if (bytes.first() == \'\\10\') { // D20-19493 特殊符号在 char 数组开头时 concat 有 bug
                text = concat(bytes[1:])
                lines = text.split("\\n")
                lines = [lastLine].append!(lines)
            } else {
                text = concat(bytes)
                lines = text.split("\\n")
                text = lastLine+lines[0]
                lines[0] = text
            }
            lastLine=lines.tail();
            lines=lines[:lines.size()-1];
            ts = temporalParse(lines.substr(0, 29), "yyyy-MM-dd HH:mm:ss.nnnnnnnnn")
            tb = table(
                ts as ts,
                lines as line
            )
            delete from tb where ts == NULL
            delete from tb where line == NULL
            if (ts.first() > endTime_) {
                break
            }
            if (ts.last() < startTime_) {
                continue
            }
            update tb set threadId = line.split(" ").at(1).split(",").at(1)
            levels = tb["line"].split(" ").at(2)
            levels = levels.substr(1, levels.strlen()-2)
            update tb set level = levels
            if ((ts.last() > startTime_ and ts.first() < startTime_) or (ts.first() < endTime_ and ts.last() > endTime_)) {
                delete from tb where ts < startTime_ or ts > endTime_
            }
            
            cnt = exec count(*) from tb where level == "ERROR"
            errorCnt += cnt
            cnt = exec count(*) from tb where level == "WARNING"
            warningCnt += cnt
            print(errorCnt + ", " + warningCnt)
        } while(numByte==maxByteSize);
        fin.close()
    }
    ret = table(1:0, `level`count, [STRING, LONG])
    insert into ret values ("ERROR", errorCnt)
    insert into ret values ("WARNING", warningCnt)
    
    return ret
}

def errorLogs(params) {
    startTime = params["startTime"]
    endTime = params["endTime"]

    logs = getServerLogEx(startTime, endTime)
    ret = select * from logs where level in params["logLevel"] and count > 0
    cnt = exec count(*) from ret where count > 0

    if (cnt > 0) {
        return (false, ret, "请检查该节点的运行日志内容。")
    } else {
        return (true, ret, NULL)
    }
}
'
params = [
    dict(`name`type, ["startTime", "TIMESTAMP"]),
    dict(`name`type, ["endTime", "TIMESTAMP"]),
    dict(`name`type`options, ["logLevel", "SYMBOL", ["ERROR", "WARNING"]])
]
version = 1
newMetric(name, displayName, group, desc, nodes, script, params, version)
go

name = "queryElapsed"
displayName = "耗时最长的前10条 SQL"
group = "1"
desc = "统计在指定时间范围内（startTime 到 endTime）执行的耗时最长的前10条 SQL。
参数说明：
- startTime：TIMESTAMP，统计范围的开始时间，默认值为上次相同方案 ID 的报告的开始时间。
- endTime：TIMESTAMP，统计范围的结束时间，默认值为当前报告的开始时间。"
nodes = NULL // NULL 指该指标不能指定节点运行，选择任一数据节点执行
script = '
def queryElapsed(params) {
    startTime_ = params["startTime"]
    endTime_ = params["endTime"]
    
    getQueryLogInner = def(startTime_, endTime_) {
		logDir = getConfig("logFile").split("/")
		logDir = logDir[:(logDir.size()-1)].concat("/")
        logDir = iif(isNull(logDir), "./", logDir)
        logFiles = select * from files(logDir, "%_job.log") where isDir == false order by filename asc
        schema = table(
            ["node","userId","sessionId","jobId","rootId","type","level","startTime","endTime","jobDesc","errorMsg"] as name,
            [
                "STRING", "STRING", "LONG", "UUID", "UUID",
                "STRING", "INT", "NANOTIMESTAMP", "NANOTIMESTAMP",
                "STRING", "STRING"
            ] as type
        )
        
		if (logFiles.size() == 0) {
			throw "Error: no job log found in " + logDir + ", maybe you haven\'t run any sql yet."
		}
        addColumn(logFiles, `startTime`endTime, [TIMESTAMP, TIMESTAMP])
        update logFiles set endTime = temporalParse(substr(filename, 0, 14), "yyyyMMddHHmmss")
        update logFiles set startTime = move(endTime, 1)
        if (!isNull(startTime_)) {
            delete from logFiles where endTime != NULL and endTime < startTime_
        }
        if (!isNull(endTime_)) {
            delete from logFiles where startTime != NULL and startTime > endTime_
        }
        
        ret = table(1:0, schema["name"], schema["type"])
        addColumn(ret, "elapseMs", DOUBLE)
        reorderColumns!(ret, ["elapseMs"])
        for (filename in logFiles["filename"]) {
            filePath = logDir + "/" + filename
            logs = loadText(filePath, schema=schema)
            if (!isNull(startTime_)) {
                logs = select * from logs where startTime >= nanotimestamp(startTime_)
            }
            if (!isNull(endTime_)) {
                logs = select * from logs where endTime <= nanotimestamp(endTime_)
            }
            res = select (endTime - startTime) \\ 1000 \\ 1000 as elapseMs, * from logs where type == "Q" order by (endTime - startTime) desc limit 10
            ret.append!(res)
        }
	
		return ret
	}

    nodes = exec name from rpc(getControllerAlias(), getClusterPerf) where mode != 1 and mode != 2
    ret = pnodeRun(getQueryLogInner{startTime_, endTime_}, nodes)
    
    res = select * from ret where type == "Q" order by elapseMs desc limit 10
	return (true, res, NULL)
}
'
params = [
    dict(`name`type, ["startTime", "TIMESTAMP"]),
    dict(`name`type, ["endTime", "TIMESTAMP"])
]
version = 1
newMetric(name, displayName, group, desc, nodes, script, params, version)
go

name = "mostQueriedDFSTables"
displayName = "访问次数最多的前10个库表"
group = "1"
desc = "统计在指定时间范围内（startTime 到 endTime）访问次数最多的前10个库表。
参数说明：
- startTime：TIMESTAMP，统计范围的开始时间，默认值为上次相同方案 ID 的报告的开始时间。
- endTime：TIMESTAMP，统计范围的结束时间，默认值为当前报告的开始时间。"
nodes = NULL // NULL 指该指标不能指定节点运行，选择任一数据节点执行
script = '
def mostQueriedDFSTables(params) {
    if (!bool(getConfig("enableDFSQueryLog"))) {
        return (false, "未配置 enableDFSQueryLog=true。", "请配置 enableDFSQueryLog=true 以支持该项检查。")
    }
    
    startTime_ = params["startTime"]
    endTime_ = params["endTime"]
    
    getQueryLogInner = def(startTime_, endTime_) {
		logDir = getConfig("logFile").split("/")
		logDir = logDir[:(logDir.size()-1)].concat("/")
        logDir = iif(isNull(logDir), "./", logDir)
        logFiles = files(logDir, "%_query.log")
        schema = table(
            ["node","userId","sessionId","jobId","rootId","type","level","time","database","table","jobDesc"] as name,
            ["STRING", "STRING", "LONG", "UUID", "UUID", "STRING", "INT", "NANOTIMESTAMP", "STRING", "STRING", "STRING"] as type
        )
		if (logFiles.size() == 0) {
			throw "Error: no query log found in " + logDir + ", maybe you haven\'t run any sql yet."
		}
        addColumn(logFiles, `startTime`endTime, [TIMESTAMP, TIMESTAMP])
        update logFiles set endTime = temporalParse(substr(filename, 0, 14), "yyyyMMddHHmmss")
        update logFiles set startTime = move(endTime, 1)
        if (!isNull(startTime_)) {
            delete from logFiles where endTime != NULL and endTime < startTime_
        }
        if (!isNull(endTime_)) {
            delete from logFiles where startTime != NULL and startTime > endTime_
        }
        
        ret = table(1:0, `database`table`count, [STRING, STRING, LONG])
        for (filename in logFiles["filename"]) {
            filePath = logDir + "/" + filename
            logs = loadText(filePath, schema=schema)
            if (!isNull(startTime_)) {
                logs = select * from logs where time >= nanotimestamp(startTime_)
            }
            if (!isNull(endTime_)) {
                logs = select * from logs where time <= nanotimestamp(endTime_)
            }
            delete from logs where database == NULL
            res = select count(*) as count from logs group by database, table order by count desc limit 10
            ret.append!(res)
        }
		return ret
	}
    nodes = exec name from rpc(getControllerAlias(), getClusterPerf) where mode != 1 and mode != 2
    ret = pnodeRun(getQueryLogInner{startTime_, endTime_}, nodes) 
    ret = select sum(count) as count from ret group by database, table order by count desc limit 10
    
	return (true, ret, NULL)
}
'
params = [
    dict(`name`type, ["startTime", "TIMESTAMP"]),
    dict(`name`type, ["endTime", "TIMESTAMP"])
]
version = 1
newMetric(name, displayName, group, desc, nodes, script, params, version)
go

name = "DFSTableDiskUsage"
displayName = "数据库写入量前10名"
group = "1"
desc = "统计在指定时间范围内（startTime 到 endTime）数据库写入量前10名。
参数说明：
- startTime：TIMESTAMP，统计范围的开始时间，默认值为上次相同方案 ID 的报告的开始时间。
- endTime：TIMESTAMP，统计范围的结束时间，默认值为当前报告的开始时间。"
nodes = NULL // NULL 指该指标不能指定节点运行，选择任一数据节点执行
script = '
def dfsPath2tableName(node, chunkId, dfsPath){
    fields=dfsPath.split("/");
    dbUrl="dfs:/" + rpc(node, getDBIdByTabletChunk{chunkId})
    res=exec tableName from listTables(dbUrl) where physicalIndex=last(fields);
    return dbUrl,res[0];
}

def DFSTableDiskUsage(params) {
    startTime = timestamp(params["startTime"])
    endTime = timestamp(params["endTime"])
    meta = select * from rpc(getControllerAlias(), getClusterChunksStatus) where lastUpdated between startTime and endTime and !file.endsWith("domain") and !file.endsWith(".tbl")
    if (meta.size() == 0) {
        return (true, NULL, NULL)
    }
    addColumn(meta, `dbName`tbName, [STRING, STRING])
    dbNames = []$STRING
    tbNames = []$STRING
    for (item in meta) {
        chunkId = item["chunkId"]
        dfsPath = item["file"]
        node = item["replicas"].split(",").first().split(":").first()
        dbName, tbName = dfsPath2tableName(node, chunkId, dfsPath)
        dbNames.append!(dbName)
        tbNames.append!(tbName)
    }
    update meta set dbName = dbNames
    update meta set tbName = tbNames
    
    f = def(item) {
        // item = meta[0]
        chunkPath = item["file"]
        dbName = item["dbName"]
        tbName = item["tbName"]
        nodes = exec name from rpc(getControllerAlias(), getClusterPerf) where mode == 0 or mode == 3
        diskGB = select sum(double(diskUsage)\\1024\\1024\\1024) diskGB
                    from pnodeRun(getTabletsMeta{chunkPath, tbName, true, -1}, nodes)
        diskGB = diskGB["diskGB"].first()
        return table(
            dbName as dbName,
            tbName as tbName,
            chunkPath as chunkPath,
            diskGB as diskGB
        )
    }
    ret = unionAll(peach(f, meta), false, true)
    delete from ret where diskGB == 0 or isNull(diskGB)
    ret = select sum(diskGB) as diskGB from ret group by dbName, tbName order by diskGB desc limit 10
    if (ret.size() == 0) {
        return (true, NULL, NULL)
    }
    return (true, ret, NULL)
}
'
params = [
    dict(`name`type, ["startTime", "TIMESTAMP"]),
    dict(`name`type, ["endTime", "TIMESTAMP"])
]
version = 1
newMetric(name, displayName, group, desc, nodes, script, params, version)
go

name = "biggestChunks"
displayName = "统计分区大小前10名"
group = "1"
desc = "统计在指定时间范围内（startTime 到 endTime）有写入记录的分区大小前10名。
参数说明：
- startTime：TIMESTAMP，统计范围的开始时间，默认值为上次相同方案 ID 的报告的开始时间。
- endTime：TIMESTAMP，统计范围的结束时间，默认值为当前报告的开始时间。"
nodes = NULL // NULL 指该指标不能指定节点运行，选择任一数据节点执行
script = '
def dfsPath2tableName(node, chunkId, dfsPath){
    fields=dfsPath.split("/");
    dbUrl="dfs:/" + rpc(node, getDBIdByTabletChunk{chunkId})
    res=exec tableName from listTables(dbUrl) where physicalIndex=last(fields);
    return dbUrl,res[0];
}

def biggestChunks(params) {
    startTime = timestamp(params["startTime"])
    endTime = timestamp(params["endTime"])
    res = table(1:0, `dbName`tbName`dfsPath`chunkId, [STRING, STRING, STRING, STRING])
    meta = select * from rpc(getControllerAlias(), getClusterChunksStatus) where lastUpdated between startTime and endTime and !file.endsWith(".tbl") and !file.endsWith("/domain")
    
    for (item in meta) {
        node = item["replicas"].split(",").first().split(":").first()
        chunkId = item["chunkId"]
        dfsPath = item["file"]
        dbName, tbName = dfsPath2tableName(node, chunkId, dfsPath)
        insert into res values (dbName, tbName, dfsPath, chunkId)
    }
    delete from res where tbName == NULL
    
    f = def(item) {
        dfsPath = item["dfsPath"]
        tbName = item["tbName"]
        nodes = exec name from rpc(getControllerAlias(), getClusterPerf) where mode == 0 or mode == 3
        diskGB = select sum(diskUsage\\1024\\1024\\1024) as diskGB
                    from pnodeRun(getTabletsMeta{dfsPath, tbName, true, -1}, nodes)
        return double(diskGB["diskGB"].first())
    }
    res_ = peach(f, res)
    update res set diskGB = res_
    res = select * from res order by diskGB desc limit 10

    return (true, res, NULL)
}
'
params = [
    dict(`name`type, ["startTime", "TIMESTAMP"]),
    dict(`name`type, ["endTime", "TIMESTAMP"])
]
newMetric(name, displayName, group, desc, nodes, script, params)
go

name = "sortKeyCount"
displayName = "排序键"
group = "1"
desc = "检查在指定时间范围内（startTime 到 endTime）有写入记录的表的排序键是否过多。当排序键过多时，需要进行哈希降维。
参数说明：
- startTime：TIMESTAMP，统计范围的开始时间，默认值为上次相同方案 ID 的报告的开始时间。
- endTime：TIMESTAMP，统计范围的结束时间，默认值为当前报告的开始时间。"
nodes = NULL // NULL 指该指标不能指定节点运行，选择任一数据节点执行
script = '
def dfsPath2tableName(node, chunkId, dfsPath){
    fields=dfsPath.split("/");
    dbUrl="dfs:/" + rpc(node, getDBIdByTabletChunk{chunkId})
    res=exec tableName from listTables(dbUrl) where physicalIndex=last(fields);
    return dbUrl,res[0];
}

def sortKeyCount(params) {
    startTime = timestamp(params["startTime"])
    endTime = timestamp(params["endTime"])
    meta = select * from rpc(getControllerAlias(), getClusterChunksStatus) where lastUpdated between startTime and endTime

    res = table(1:0, `dbName`tbName`dfsPath`chunkId, [STRING, STRING, STRING, STRING])
    for (item in meta) {
        node = item["replicas"].split(",").first().split(":").first()
        chunkId = item["chunkId"]
        dfsPath = item["file"]
        dbName, tbName = dfsPath2tableName(node, chunkId, dfsPath)
        insert into res values (dbName, tbName, dfsPath, chunkId)
    }
    ret = table(1:0, `dbName`tbName`maxSortKeyEntryCount, [STRING, STRING, INT])
    for (info in getClusterDFSTables()) {
        // info = getClusterDFSTables()[10]
        s = info.split("/") 
        dbName_ = "dfs://" + s[2]
        tbName_ = s[3]
        chunkIds = exec chunkId from res where dbName == dbName_ and tbName == tbName_ limit 1024
        nodes = exec name from rpc(getControllerAlias(), getClusterPerf) where mode == 0 or mode == 3
        ret_ = select max(sortKeyEntryCount) as maxSortKeyEntryCount from pnodeRun(getTSDBDataStat{, , chunkIds}, nodes) group by dbName, tableName 
        ret.append!(ret_)
    }
    ret = select * from ret where maxSortKeyEntryCount >= 1000 order by maxSortKeyEntryCount desc
    
    if (ret.size() == 0) {
        return (true, NULL, NULL)
    } else {
        return (false, "存在 " + string(ret.size()) + " 张表排序键超过 1000，部分统计结果如下：", "建议重建表并对排序键进行哈希降维处理。", select top 10 * from ret)
    }
}
'
params = [
    dict(`name`type, ["startTime", "TIMESTAMP"]),
    dict(`name`type, ["endTime", "TIMESTAMP"])
]
version = 1
newMetric(name, displayName, group, desc, nodes, script, params, version)
go

name = "checkConfigs::commonDolphinDBConfig"
displayName = "常见配置项检查"
group = "1"
desc = "检查常见的 DolphinDB 配置项错误。"
nodes = NULL // NULL 指该指标不能指定节点运行，选择任一数据节点执行
script = '
module readConfigs

def readAllLines(filepath) {
    fin = file(filepath)
    ret = []$STRING
    
    do {
        x=fin.readLine()
        if(x.isNull()) break
        if (x.strlen() != 0) {
            ret.append!(x)
        }
    } while(true)
    
    return ret
}

def loadAgentConfigs(nodeAlias) {
    res = select host, port from rpc(getControllerAlias(),getClusterPerf) where name == nodeAlias
    host_ = res["host"].first()
    port_ = res["port"].first()
    conn = xdb(host_, port_)
    cfg = conn(getConfig)
    filepath = cfg.config
    name = exec first(name) from rpc(getControllerAlias(),getClusterPerf) where host == host_ and (mode == 0 or mode == 4)
    ret = rpc(name, readAllLines{filepath})
    
    return ret
}

def loadRawConfigsOfCluster() {
    ret = dict(STRING, ANY)
    isSingle = (exec count(*) from rpc(getControllerAlias(), getClusterPerf{true}) where mode == 3) == 1
    
    if (isSingle) {
        ret["dolphindb.cfg"] = loadClusterNodesConfigs() // 似乎在 2.00.13 之前不支持单节点
    } else {
        controllerNames = exec name from rpc(getControllerAlias(), getClusterPerf{true}) where mode == 2
        controllerConfigsDict = dict(STRING, ANY)
        for (controllerName in controllerNames) {
            controllerConfigs = rpc(controllerName, loadControllerConfigs)
            controllerConfigsDict[controllerName] = controllerConfigs
        }
        controllerConfigsDict["leader"] = getControllerAlias()
        ret["controller.cfg"] = controllerConfigsDict
        agentNames = exec name from rpc(getControllerAlias(), getClusterPerf{true}) where mode == 1
        agentConfigsDict = dict(STRING, ANY)
        for (agentName in agentNames) {
            agentConfigs = loadAgentConfigs(agentName)
            agentConfigsDict[agentName] = agentConfigs
        }
        ret["agent.cfg"] = agentConfigsDict
        ret["cluster.cfg"] = rpc(getControllerAlias(), loadClusterNodesConfigs)
        ret["cluster.nodes"] = rpc(getControllerAlias(), getClusterNodesCfg)
    }

    return ret
}

def loadRawConfigsOfDir(dir) {
    ret = dict(STRING, ANY)
    controllerConfigsDict = dict(STRING, ANY)
    agentConfigsDict = dict(STRING, ANY)
    filesInfo = select * from files(dir) where isDir == false and (filename.endsWith(".cfg") or filename.endsWith(".nodes"))

    if (filesInfo.size() == 0) {
        throw "config file not found at " + dir
    }

    for (item in filesInfo) {
        filename = item["filename"]
        filepath = dir + "/" + filename
        lines = readAllLines(filepath)
        
        if (filename == "cluster.cfg") {
            ret["cluster.cfg"] = lines
        } else if (filename == "cluster.nodes") {
            ret["cluster.nodes"] = lines
        } else {
            nodeAlias = NULL
            mode = NULL
            for (line in lines) {
                if (line.startsWith("localSite")) {
                    nodeAlias = line.split(":").last()
                } else if (line.startsWith("mode")) {
                    mode = line.split("=").last()
                }
            }
            if (nodeAlias == NULL or mode == NULL) {
                continue
            }
            if (mode == "controller") {
                controllerConfigsDict[nodeAlias] = lines
            } else if (mode == "agent") {
                agentConfigsDict[nodeAlias] = lines
            } else if (mode == "single") {
                ret["dolphindb.cfg"] = lines
            }
        }
    }
    ret["controller.cfg"] = controllerConfigsDict
    ret["agent.cfg"] = agentConfigsDict

    return ret
}

def loadRawConfigs(dir=NULL) {
    if (dir == NULL) {
        ret = loadRawConfigsOfCluster()
    } else {
        ret = loadRawConfigsOfDir(dir)
    }
    if (ret.keys().size() == 1 and ret.keys().first() == "dolphindb.cfg") {
        ret["mode"] = "single"
    } else {
        ret["mode"] = "cluster"
    }
    
    return ret
}

def parseConfigs(rawConfigs) {
    ret = dict(STRING, ANY)

    configLinesToDict = def (lines) {
        d = dict(STRING, ANY)
        for (line in lines) {
            s = line.split("=")
            if (s.size() >= 2) {
                k = s.first().strip()
                v = s.last().strip()
                d[k] = v
            }
        }
        return d
    }

    for (key in ["controller.cfg", "agent.cfg"]) {
        if (!isVoid(rawConfigs[key])) {
            ret[key] = dict(STRING, ANY)
            for (name in rawConfigs[key].keys()) {
                if (name != "leader") {
                    ret[key][name] = configLinesToDict(rawConfigs[key][name])
                } else {
                    ret[key][name] = rawConfigs[key][name]
                }
            }
        }
    }
    for (key in ["dolphindb.cfg", "cluster.cfg"]) {
        if (!isVoid(rawConfigs[key])) {
            ret[key] = configLinesToDict(rawConfigs[key])
        }
    }

    if (!isVoid(rawConfigs["cluster.nodes"])) {
        tb = table(1:0, `host`port`nodeAlias`nodeType, [STRING, INT, STRING, SYMBOL])
        if ("leader" in rawConfigs["controller.cfg"].keys()) {
            startIndex = 0
        } else {
            startIndex = 1 // 跳过文件首行的 localSite,mode
        }
        for (i in (startIndex..(rawConfigs["cluster.nodes"].size()-1))) {
            item = rawConfigs["cluster.nodes"][i]
            s1 = item.split(":")
            if (s1.size() != 3 and s1.size() != 4) {
                throw "cluster.nodes 行非法：" + item
            }
            host = s1[0]
            port = int(s1[1])
            s2 = s1[2].split(",")
            if (s2.size() != 2 and s2.size() != 3) {
                throw "cluster.nodes 行非法：" + item
            }
            nodeAlias = s2[0]
            nodeType = s2[1]
            insert into tb values (host, port, nodeAlias, nodeType)
        }
        ret["cluster.nodes"] = tb
    }

    ret["mode"] = rawConfigs["mode"]
    
    return ret
}

def getControllerConfigs(parsedConfigs, nodeAlias=NULL) {
    if (parsedConfigs["mode"] == "single") {
        return parsedConfigs["dolphindb.cfg"]
    }

    if (isNull(nodeAlias)) {
        if (isVoid(parsedConfigs["controller.cfg"]["leader"])) {
            nodeAlias_ = parsedConfigs["controller.cfg"].keys().first()
        } else {
            nodeAlias_ = parsedConfigs["controller.cfg"]["leader"]
        }
    } else {
        nodeAlias_ = nodeAlias
    }
    
    return parsedConfigs["controller.cfg"][nodeAlias_]
}

def getAgentConfigs(parsedConfigs, nodeAlias=NULL) {
    if (parsedConfigs["mode"] != "cluster") {
        throw "no agent.cfg for mode: " + parsedConfigs["mode"]
    }

    nodeAlias_ = iif(isNull(nodeAlias), parsedConfigs["agent.cfg"].keys().first(), nodeAlias)
    return parsedConfigs["agent.cfg"][nodeAlias_]
}

def getClusterConfigs(parsedConfigs) {
    if (parsedConfigs["mode"] == "single") {
        return parsedConfigs["dolphindb.cfg"]
    }

    return parsedConfigs["cluster.cfg"]
}

def getClusterNodes(parsedConfigs, nodeType=NULL) {
    if (parsedConfigs["mode"] != "cluster") {
        throw "no cluster.nodes for mode: " + parsedConfigs["mode"]
    }
    
    ret = parsedConfigs["cluster.nodes"]
    if (nodeType != NULL) {
        nodeType_ = nodeType
        ret = select * from ret where nodeType == nodeType_
    }

    return ret
}

def getSingleConfigs(parsedConfigs) {
    if (parsedConfigs["mode"] != "single") {
        throw "no dolphindb.cfg for mode: " + parsedConfigs["mode"]
    }

    return parsedConfigs["dolphindb.cfg"]
}

def getControllerAliases(parsedConfigs) {
    return parsedConfigs["controller.cfg"].keys()
}

def getAgentAliases(parsedConfigs) {
    return parsedConfigs["agent.cfg"].keys()
}

def getConfigEx(parsedConfigs, key, nodeAlias) {
    if (parsedConfigs["mode"] == "single") {
        return parsedConfigs["dolphindb.cfg"][key] // 单节点必然没有 节点名.配置项
    }

    nodeAlias_ = nodeAlias
    nodeType = exec first(nodeType) from parsedConfigs["cluster.nodes"] where nodeAlias = nodeAlias_
    if (nodeType == "controller") {
        cfg = parsedConfigs["controller.cfg"][nodeAlias]
    } else if (nodeType == "agent") {
        cfg = parsedConfigs["agent.cfg"][nodeAlias]
    } else {
        cfg = parsedConfigs["cluster.cfg"]
    }

    ret1 = NULL
    ret2 = NULL
    for (key_ in cfg.keys()) {
        if (key_ == key) {
            ret1 = cfg[key_]
        } else if (key_.startsWith(nodeAlias) and key_.split(".").last() == key) {
            ret2 = cfg[key_]
        }
    }

    return iif(isNull(ret2), ret1, ret2)
}

def getClusterConfigsEx(parsedConfigs, key) {
    clusterNodes = select * from getClusterNodes(parsedConfigs) where nodeType = "datanode" or nodeType == "computenode"
    cfgs = []$STRING
    for (nodeAlias in clusterNodes["nodeAlias"]) {
        cfg = getConfigEx(parsedConfigs, key, nodeAlias)
        cfgs.append!(cfg)
    }
    update clusterNodes set value = cfgs
    return clusterNodes
}

def saveConfigs(rawConfigs, dir) {
    if (!exists(dir)) {
        throw "dir " + dir + " not exist!"
    }

    for (cfgFilename in rawConfigs.keys()) {
        if (cfgFilename == "controller.cfg" or cfgFilename == "agent.cfg") {
            for (nodeAlias in rawConfigs[cfgFilename].keys()) {
                filepath = dir + "/" + nodeAlias + "_" + cfgFilename
                f = file(filepath, "w")
                for (line in rawConfigs[cfgFilename][nodeAlias]) {
                    f.writeLine(line)
                }
                f.close()
            }
        } else {
            filepath = dir + "/" + cfgFilename
            f = file(filepath, "w")
            for (line in rawConfigs[cfgFilename]) {
                f.writeLine(line)
            }
            f.close()
        }
    }
}
go

module checkConfigs

def datasync(parsedConfigs) {
    controllerConfigs = readConfigs::getControllerConfigs(parsedConfigs)
    clusterConfigs = readConfigs::getClusterConfigs(parsedConfigs)

    if (int(controllerConfigs["dataSync"]) == 1) {
        if (isVoid(clusterConfigs["TSDBCacheEngineSize"]) and (isVoid(clusterConfigs["chunkCacheEngineMemSize"]) or isVoid(clusterConfigs["OLAPCacheEngineSize"]))) {
            filename = iif(parsedConfigs["mode"] == "cluster", "cluster.cfg", "dolphindb.cfg")
            throw "controller.cfg 配置 dataSync=1 时，必须同时配置 cluseter.cfg 的 TSDBCacheEngineSize 或 OLAPCacheEngineSize"
        }
    } else {
        if (!isVoid(clusterConfigs["TSDBCacheEngineSize"]) or !(isVoid(clusterConfigs["chunkCacheEngineMemSize"]) and isVoid(clusterConfigs["OLAPCacheEngineSize"]))) {
            filename = iif(parsedConfigs["mode"] == "cluster", "controller.cfg", "dolphindb.cfg")
            throw "cluseter.cfg 配置 TSDBCacheEngineSize 或 OLAPCacheEngineSize 时，必须同时配置 controller.cfg 的 dataSync=1"
        }
    }
}

def volumes(parsedConfigs) {
    if (parsedConfigs["mode"] == "single") {
        return
    }

    key = "volumes"
    clusterNodes = select * from readConfigs::getClusterConfigsEx(parsedConfigs, key) where nodeType == "datanode"
    res = select count(*) as count from clusterNodes where value != NULL group by host, value
    res = select * from res where count > 1
    if (res.size() > 0) {
        errInfo = select host, nodeAlias, value from res inner join clusterNodes on res.host == clusterNodes.host and res.value == clusterNodes.value
        throw "cluster.cfg 中存在同一台机器上的不同数据节点的 " + key + " 配置了相同的值：\n" + string(errInfo)
    }
}

def persistenceDir(parsedConfigs) {
    if (parsedConfigs["mode"] == "single") {
        return
    }

    key = "persistenceDir"
    clusterNodes = select * from readConfigs::getClusterConfigsEx(parsedConfigs, key)
    res = select count(*) as count from clusterNodes where value != NULL group by host, value
    res = select * from res where count > 1
    if (res.size() > 0) {
        errInfo = select host, nodeAlias, value from res inner join clusterNodes on res.host == clusterNodes.host and res.value == clusterNodes.value
        throw "存在同一台机器上的不同数据节点的 " + key + " 配置了相同的值：\n" + string(errInfo)
    }
}

def newValuePartitionPolicy(parsedConfigs) {
    if (parsedConfigs["mode"] == "single") {
        configs = readConfigs::getSingleConfigs(parsedConfigs)
        if (configs["newValuePartitionPolicy"] != "add") {
            throw "建议将 newValuePartitionPolicy 配置为 add，当前值：" + configs["newValuePartitionPolicy"]
        }
        return
    }

    res = select * from readConfigs::getClusterConfigsEx(parsedConfigs, "newValuePartitionPolicy") where value != "add"
    if (res.size() > 0) {
        throw "建议将 newValuePartitionPolicy 配置项配置为 add，当前值：\n" + res
    }
}

def checkSites(parsedConfigs) {
    if (parsedConfigs["mode"] == "single") {
        return
    }

    nodeAliases = exec nodeAlias from readConfigs::getClusterNodes(parsedConfigs, "controller")
    controllerCnt = nodeAliases.size()
    for (nodeAlias in nodeAliases) {
        cfgs = readConfigs::getAgentConfigs(parsedConfigs, nodeAlias)
        if (isVoid(cfgs)) {
            continue
        }
        localSite = cfgs["localSite"]
        s = localSite.split(":")
        if (s.size() != 3) {
            throw "控制节点 " + nodeAlias + " 的 localSite 格式非法：" + localSite + localSite
        }
        
        host_ = s[0]
        port_ = int(s[1])
        nodeAlias_ = s[2]
        cnt = exec count(*) from readConfigs::getClusterNodes(parsedConfigs) where host == host_ and port == port_ and nodeAlias == nodeAlias_
        if (cnt == 0) {
            throw "控制节点 " + nodeAlias + " 的 localSite 在 cluster.nodes 中不存在"
        }
    }

    if (parsedConfigs["mode"] == "single") {
        return
    }

    nodeAliases = exec nodeAlias from readConfigs::getClusterNodes(parsedConfigs, "agent")
    for (nodeAlias in nodeAliases) {
        cfgs = readConfigs::getAgentConfigs(parsedConfigs, nodeAlias)
        if (isVoid(cfgs)) {
            continue
        }
        localSite = cfgs["localSite"]
        s = localSite.split(":")
        if (s.size() != 3) {
            throw "代理节点 " + nodeAlias + " 的 localSite 格式非法：" + localSite
        }

        host_ = s[0]
        port_ = int(s[1])
        nodeAlias_ = s[2]
        cnt = exec count(*) from readConfigs::getClusterNodes(parsedConfigs) where host == host_ and port == port_ and nodeAlias == nodeAlias_
        if (cnt == 0) {
            throw "代理节点 " + nodeAlias + " 的 localSite 在 cluster.nodes 中不存在"
        }

        controllerSite = cfgs["controllerSite"]
        s = localSite.split(":")
        if (s.size() != 3) {
            throw "代理节点 " + nodeAlias + " 的 controllerSite 格式非法：" + localSite
        }

        host_ = s[0]
        port_ = int(s[1])
        nodeAlias_ = s[2]
        cnt = exec count(*) from readConfigs::getClusterNodes(parsedConfigs) where host == host_ and port == port_ and nodeAlias == nodeAlias_
        if (cnt == 0) {
            throw "代理节点 " + nodeAlias + " 的 controllerSite 在 cluster.nodes 中不存在"
        }

        sites = cfgs["sites"]
        if (controllerCnt > 1 and isVoid(sites)) {
            throw "代理节点 " + nodeAlias + " 未配置 sites 配置项"
        }

        
        if (!isVoid(sites)) {
            s_ = sites.split(",")
            controllerNodeAliases = []$STRING
            for (item in s_) {
                s = item.split(":")
                if (s_.size() != 4) {
                    throw "代理节点 " + nodeAlias + " 的 sites 格式非法"
                }

                host_ = s[0]
                port_ = int(s[1])
                nodeAlias_ = s[2]
                type_ = s[3]
                if (type_ == "controller") {
                    controllerNodeAliases.append!(nodeAlias_)
                } 
                cnt = exec count(*) from readConfigs::getClusterNodes(parsedConfigs) where host == host_ and port == port_ and nodeAlias == nodeAlias_
                if (cnt == 0) {
                    throw "代理节点 " + nodeAlias + " 的 sites 中指定的" + host_ + ":" + port_ + ":" + nodeAlias_ + " 在 cluster.nodes 中不存在"
                }
            }

            s = s_[0].split(":")
            nodeAlias_ = s[2]
            if (nodeAlias_ != nodeAlias) {
                throw "代理节点 " + nodeAlias + " 的 sites 配置项的第一个节点不等于自身"
            }

            if (set(controllerNodeAliases).size() != controllerCnt) {
                throw "代理节点 " + nodeAlias + " 的 sites 配置项的控制节点数不等于所有控制节点数"
            }
        }
    }
}

def lanCluster(parsedConfigs) {
    isLanIp = def (str) {
        s = str.split(":")

        if (s.size() != 4) {
            return false
        }

        if (s[0] == "localhost") {
            return false 
        }

        for (item in s) {
            if (!isDigit(item) or !(0 <= int(item) <= 255)) {
                return false
            }
        }

        s0 = int(s[0])
        s1 = int(s[1])

        if ((s0 == 10) or (s0 == 172 and 16 <= s1 <= 31) or (s0 == 192 and s1 == 168)) {
            return true
        }

        return false
    }

    // 单节点没心跳
    if (parsedConfigs["mode"] == "single") {
        return
    }

    lanCluster = dict(STRING, INT)
    nodeAliases = exec nodeAlias from readConfigs::getClusterNodes(parsedConfigs, "controller")
    for (nodeAlias in nodeAliases) {
        controllerConfigs = readConfigs::getControllerConfigs(parsedConfigs)
        if (!isVoid(controllerConfigs["lanCluster"])) {
            lanCluster[nodeAlias] = int(controllerConfigs["lanCluster"])
        }
    }
    nodeAliases = exec nodeAlias from readConfigs::getClusterNodes(parsedConfigs, "agent")
    for (nodeAlias in nodeAliases) {
        agentConfigs = readConfigs::getAgentConfigs(parsedConfigs)
        if (!isVoid(agentConfigs["lanCluster"])) {
            lanCluster[nodeAlias] = int(agentConfigs["lanCluster"])
        }
    }
    nodeAliases = exec nodeAlias from readConfigs::getClusterNodes(parsedConfigs) where nodeType == "datanode" or nodeType == "computenode"
    for (nodeAlias in nodeAliases) {
        cfgs = readConfigs::getClusterConfigsEx(parsedConfigs, "lanCluster")
        if (cfgs.size() > 0) {
            for (item in cfgs) {
                lanCluster[item["nodeAlias"]] = int(item["value"])
            }
        }
    }
    v = set(lanCluster.values())
    if (v.size() != 1) {
        throw "集群中所有节点的 lanCluster 配置值不一致：\n" + lanCluster
    } else {
        lanCluster = lanCluster.values().first()
    }

    if (lanCluster == 0) {
        return
    }
    
    nodeAliases = exec nodeAlias from readConfigs::getClusterNodes(parsedConfigs, "controller")
    for (nodeAlias in nodeAliases) {
        controllerConfigs = readConfigs::getControllerConfigs(parsedConfigs, nodeAlias)
        if (isVoid(controllerConfigs)) {
            continue
        }
        localSite = controllerConfigs["localSite"]
        host = localSite.split(":").first()
        if (!isLanIp(host)) {
            throw nodeAlias + " 的 localSite 配置的 " + host + " 不是局域网 IP"
        }
    }

    nodeAliases = exec nodeAlias from readConfigs::getClusterNodes(parsedConfigs, "agent")
    for (nodeAlias in nodeAliases) {
        agentConfigs = readConfigs::getAgentConfigs(parsedConfigs, nodeAlias)
        if (isVoid(agentConfigs)) {
            continue
        }
        localSite = agentConfigs["localSite"]
        host = localSite.split(":").first()
        if (!isLanIp(host)) {
            throw nodeAlias + " 的 localSite 配置的 " + host + " 不是局域网 IP"
        }

        if (!isVoid(agentConfigs["sites"])) {
            s = agentConfigs["sites"].split(",")

            for (item in s) {
                host = item.split(":").first()
                if (!isLanIp(host)) {
                    throw nodeAlias + " 的 localSite 配置的 " + host + " 不是局域网 IP"
                }
            }
        }
    }

    for (host in readConfigs::getClusterNodes(parsedConfigs)["host"]) {
        if (!isLanIp(host)) {
            throw "cluster.nodes 配置的 " + host + " 不是局域网 IP"
        }
    }
}

def dfsHAMode(parsedConfigs) {
    if (parsedConfigs["mode"] == "single") {
        return
    }

    cnt = exec count(*) from readConfigs::getClusterNodes(parsedConfigs, "controller")
    if (cnt > 1) {
        nodeAliases = exec nodeAlias from readConfigs::getClusterNodes(parsedConfigs, "controller")
        for (nodeAlias in nodeAliases) {
            controllerConfigs = readConfigs::getControllerConfigs(parsedConfigs, nodeAlias)
            if (isVoid(controllerConfigs)) {
                continue
            }
            if (controllerConfigs["dfsHAMode"] != "Raft") {
                throw nodeAlias + " 的 dfsHAMode 未配置为 Raft"
            }
        } 
    }
}

def checkClusterNodes(parsedConfigs) {
    if (parsedConfigs["mode"] == "single") {
        return
    }

    clusterNodes = readConfigs::getClusterNodes(parsedConfigs)
    res = select count(*) as count from clusterNodes group by nodeAlias
    res = select * from res where count > 1

    if (res.size() > 0) {
        throw "cluster.nodes 存在重复的节点别名：\n" + res
    }
}

def dfsReplicaReliabilityLevel(parsedConfigs) {
    controllerConfigs = readConfigs::getControllerConfigs(parsedConfigs)
    if (int(controllerConfigs["dfsReplicaReliabilityLevel"]) != 1) {
        return
    }

    res = select count(*) as count from readConfigs::getClusterNodes(parsedConfigs) where nodeType == "datanode" group by host
    res = select * from res where count > 1
    if (res.size() > 0) {
        throw "dfsReplicaReliabilityLevel=1 时，cluster.nodes 存在多个数据节点在同一机器：\n" + string(res)
    }
}

def checkALIAS(parsedConfigs) {
    if (parsedConfigs["mode"] == "single") {
        return
    }

    nodeAliases = exec nodeAlias from readConfigs::getClusterNodes(parsedConfigs, "controller")
    for (nodeAlias in nodeAliases) {
        controllerConfigs = readConfigs::getControllerConfigs(parsedConfigs, nodeAlias)
        if (isVoid(controllerConfigs)) {
            continue
        }

        for (key in controllerConfigs.keys()) {
            if (controllerConfigs[key].strFind("<ALIAS>") != -1) {
                throw nodeAlias + " 的 " + key + "=" + controllerConfigs[key] + " 配置项使用了 <ALIAS> ，这会导致配置无效" 
            }
        }
    }

    clusterConfigs = readConfigs::getClusterConfigs(parsedConfigs)
    for (key in clusterConfigs.keys()) {
        if (key.strFind(".") != -1 and clusterConfigs[key].strFind("<ALIAS>") != -1) {
            throw "cluster.cfg 的 " + key + "=" + clusterConfigs[key] + " 配置项同时使用了节点别名和 <ALIAS>，这会导致配置无效" 
        }
    }
}

def commonDolphinDBConfig(params) {
    rawConfigs = readConfigs::loadRawConfigs()
    parsedConfigs = readConfigs::parseConfigs(rawConfigs)
    funcNames = exec name from defs("checkConfigs%") where name != "checkConfigs::commonDolphinDBConfig"

    ret = table(1:0, `project`errMsg, [STRING, STRING])
    for (funcName in funcNames) {
        try {
            funcByName(funcName)(parsedConfigs)
        } catch(err) {
            insert into ret values (funcName, string(err.last()))
        }
    }

    for (item in ret) {
        print(item["errMsg"])
        print("\n")
    }

    if (ret.size() > 0) {
        return (false, ret, "请根据错误信息检查配置文件。")
    }
    return (true, NULL, NULL)
}
'
newMetric(name, displayName, group, desc, nodes, script)
go

// -------------- group 2 -------------------
name = "coredump"
displayName = "core 文件"
group = "2"
desc = "检查指定时间范围内（startTime 到 endTime）是否生成了 core 文件。
参数说明：
- startTime：TIMESTAMP，统计范围的开始时间，默认值为上次相同方案 ID 的报告的开始时间。
- endTime：TIMESTAMP，统计范围的结束时间，默认值为当前报告的开始时间。"
nodes = [0, 2, 3, 4]
script = '
def coredump(params) {
    if (getOS() != "linux") {
        throw "不支持在非 linux 系统上检查 coredump。"
    }
    if (!bool(getConfig("enableShellFunction"))) {
        return (false, "未配置 enableShellFunction=true。", "请配置 enableShellFunction=true 以支持该项检查。")
    }
    
    startTime = params["startTime"]
    endTime = params["endTime"]
    tmpFilename = "autoInspection_coredump_" + getNodeAlias() + "_" + temporalFormat(now(), "yMdHmsSSS") + "_tmp.txt"
    shell("cat /proc/sys/kernel/core_pattern > " + tmpFilename)
    f = file(tmpFilename)
    line = readLine(f)
    f.close()
    if (line.startsWith("/")) { // 绝对路径
        s = line.split("/")
        dir = s[0:(s.size()-1)].concat("/")
    } else if (char(line[0]).isAlpha()) { // 形如 core-%e，生成 coredump 在当前目录
        shell("pwd > " + tmpFilename)
        f = file(tmpFilename)
        dir = readLine(f)
        f.close()
    } else {
        rm(tmpFilename)
        return (false, "不支持自动检测的 core_pattern: " + line, "请参考《节点宕机》教程配置 coredump。")
    }
    
    info = select * from files(dir) where isDir == false and lastModified >= startTime and lastModified <= endTime
    
    if (info.size() == 0) {
        rm(tmpFilename)
        return (true, NULL, NULL)
    }
    
    ret = table(1:0, `filePath`lastModified, [STRING, TIMESTAMP])
    for (item in info) {
        // item = info[0]
        filename = item["filename"]
        filePath = dir + "/" + filename
        shell("file " + filePath + " > " + tmpFilename)
        f = file(tmpFilename)
        line = readLine(f)
        f.close()
        
        if (strFind(line, "core") != -1 and strFind(line, "dolphindb") != -1) {
            insert into ret values (filePath, item["lastModified"])
        }
    }
    ret = select * from ret order by lastModified desc
    rm(tmpFilename)
    
    ret = select count(*) as "coredump 文件数", first(filePath) as "最新文件路径" from ret group by date(lastModified) as "日期"
    
    if (ret.size() == 0) {
        return (true, NULL, NULL)
    } else {
        return (false, ret, "请检查 coredump 文件内容。")
    }
}
'
params = [
    dict(`name`type, ["startTime", "TIMESTAMP"]),
    dict(`name`type, ["endTime", "TIMESTAMP"])
]
newMetric(name, displayName, group, desc, nodes, script, params)
go

name = "commonSystemConfig"
displayName = "操作系统配置项"
group = "2"
desc = "检查 Linux 操作系统的常见配置项。
参数说明：
- logLevel：STRING 数组，统计的日志等级，可取值：ERROR，WARNING。"
nodes = [0, 2, 3, 4]
script = '
def commonSystemConfig(params) {
    if (getOS() != "linux") {
        throw "不支持在非 Linux 系统上检查配置项。"
    }
    if (!bool(getConfig("enableShellFunction"))) {
        return (false, "未配置 enableShellFunction=true。", "请配置 enableShellFunction=true 以支持该项检查。")
    }
    
    ret = table(1:0, `command`returnValue`level`suggestion, [STRING, STRING, SYMBOL, STRING])
    cmd = "gcc --version"
    res = shell(cmd)
    if (res != 0) {
        insert into ret values (cmd, res, "ERROR", "请检查 gcc 安装情况。")
    }
    
    cmd = "ulimit -c"
    res = shell("ulimit -c")
    if (res != 0) {
        insert into ret values (cmd, res, "ERROR", "请检查 ulimit -c 配置。")
    }
    
    tmpFilename = "autoInspection_commonSystemConfig_" + getNodeAlias() + "_" + temporalFormat(now(), "yMdHmsSSS") + "_tmp.txt"
    shell("cat /proc/sys/kernel/core_pattern > " + tmpFilename)
    f = file(tmpFilename)
    line = readLine(f)
    f.close()
    dir = NULL
    if (line.startsWith("/")) { // 绝对路径
        s = line.split("/")
        dir = s[0:(s.size()-1)].concat("/")
    } else if (char(line[0]).isAlpha()) { // 形如 core-%e，生成 coredump 在当前目录
        shell("pwd > " + tmpFilename)
        f = file(tmpFilename)
        dir = readLine(f)
        f.close()
    }
    if (!isNull(dir)) {
        folderName = "testCoredump" + temporalFormat(now(), "yMdHmsSSS")
        folderPath = dir + "/" + folderName
        try {
            mkdir(folderPath) 
        } catch(err) {
            insert into ret values (folderPath, err, "ERROR", "请检查 core_pattern 目录 " + dir + "是否有写入权限。")
        }
        try {
            rmdir(folderPath)
        } catch(err) {}
    }
    
    cmd = "ulimit -n > " + tmpFilename
    res = shell(cmd)
    if (res != 0) {
        insert into ret values ("ulimit -n", res, "ERROR", "请检查 ulimit -n 配置。")
    } else {
        f = file(tmpFilename)
        line = readLine(f)
        f.close()
        if (int(line) < 102400) {
            insert into ret values ("ulimit -n", line, "WARNING", "ulimit -n 值小于 102400，请调大 ulimit -n 配置值。")
        }
    }
    
    if (!("WARNING" in params["logLevel"])) {
        rm(tmpFilename)
        if (ret.size() > 0) {
            return (false, ret, NULL)
        } else {
            return (true, NULL, NULL)
        }
    }
    
    volumesCfg = getConfig("volumes")
    if (volumesCfg.form() == 0) {
        volumesCfg = [volumesCfg]
    }
    for (volumeCfg in volumesCfg) {
        // volumeCfg = volumesCfg[0]
        shell("df -hT " + volumeCfg + " > " + tmpFilename)
        if (res != 0) {
            continue
        }
        f = file(tmpFilename)
        line = readLine(f)
        line = readLine(f) // 文件类型在第二行
        f.close()
        if (line.strFind("xfs") == -1) {
            insert into ret values ("df -hT " + volumeCfg, line, "WARNING", "volumes 配置项值所在的硬盘格式不为 xfs，建议将其格式化为 xfs，以避免 inode 满的问题。")
        }
    }
    
    cmd = "gdb --version"
    res = shell(cmd)
    if (res != 0) {
        insert into ret values (cmd, res, "WARNING", "建议安装 gdb 以在宕机时查看堆栈。请检查 gdb 安装情况。")
    }
    
    cmd = "pstack"
    res = shell(cmd)
    if (res != 256) {
        insert into ret values (cmd, res, "WARNING", "建议安装 pstack 便于查看节点进程内部执行状态。请检查 pstack 安装情况。")
    }
    
    cnt = exec count(*) from rpc(getControllerAlias(), getClusterPerf) where mode == 3
    if (cnt == 0) { // 集群
        res = shell("yum --version")
        if (res == 0) {
            cmd = "systemctl status ntpd" // centos
            res = shell(cmd)
            
        } else { // ubuntu
            cmd = "systemctl status ntp" 
            res = shell(cmd)
        }
        if (res != 0) {
            insert into ret values (cmd, res, "WARNING", "在集群模式下，建议配置 NTP 以确保机器间时间同步。请检查 NTP 的安装和启动状态。")
        }
    }
    
    cmd = "swapon --show"
    res = shell(cmd)
    if (res != 0) {
        insert into ret values (cmd, res, "WARNING", "内存充足时，建议关闭 swap 以提升性能。")
    }
    
    rm(tmpFilename)
    if (ret.size() > 0) {
        return (false, ret, NULL)
    } else {
        return (true, NULL, NULL)
    }
}
'
params = [
    dict(`name`type`options, ["logLevel", "SYMBOL", ["ERROR", "WARNING"]])
]
newMetric(name, displayName, group, desc, nodes, script, params)
go
